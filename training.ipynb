{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "8504db10",
            "metadata": {},
            "outputs": [],
            "source": [
                "import re\n",
                "import csv\n",
                "import os\n",
                "import json\n",
                "import datetime\n",
                "import typing as T\n",
                "import functools\n",
                "from copy import deepcopy\n",
                "\n",
                "import torch\n",
                "import plotly.express as px\n",
                "import pytorch_lightning as pl\n",
                "import mlflow\n",
                "import pandas as pd\n",
                "\n",
                "import mtgradient\n",
                "from mtgradient import processing, datasets, models"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "9c5cfb73",
            "metadata": {},
            "outputs": [],
            "source": [
                "%load_ext nb_black"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "52783f9f",
            "metadata": {},
            "outputs": [],
            "source": [
                "# ! pip install mlflow\n",
                "mlflow.pytorch.autolog(log_models=False, log_every_n_step=100)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "12c758de",
            "metadata": {},
            "outputs": [],
            "source": [
                "###################################\n",
                "# Draft config\n",
                "# -- location of raw data\n",
                "# -- location to cache dataset\n",
                "# -- time split\n",
                "###################################\n",
                "\n",
                "# draft_csv_path = \"data/draft_data_public.NEO.PremierDraft.csv\"\n",
                "draft_csv_path = \"data/HBG/draft_data_public.HBG.PremierDraft.csv\"\n",
                "# draft_csv_path = \"tests/testdata/test_premier_draft_hbg.csv\"\n",
                "# draft_csv_path = \"tests/testdata/test_premier_draft.csv\"\n",
                "\n",
                "# cache_path = \"data/cached/neo_premier_draft\"\n",
                "cache_path = \"data/cached/hbg_premier_draft/\"\n",
                "# cache_path = \"tests/testdata/\"\n",
                "\n",
                "# test_split_cutoff = pd.Timestamp(datetime.date(2022, 3, 11))\n",
                "test_split_cutoff = pd.Timestamp(datetime.date(2022, 7, 28))\n",
                "recent_game_cutoff = test_split_cutoff - datetime.timedelta(10)\n",
                "\n",
                "LOAD_CACHED = True"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "c459bccf",
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "a314750d",
            "metadata": {
                "scrolled": true
            },
            "outputs": [],
            "source": [
                "if not LOAD_CACHED:\n",
                "    parsed_data, card_ids = processing.parse_csv(draft_csv_path, verbose=True)\n",
                "    os.makedirs(cache_path, exist_ok=True)\n",
                "    processing.persist_processed_dataset(cache_path, parsed_data, card_ids)\n",
                "else:\n",
                "    parsed_data, card_ids = processing.load_processed_dataset(cache_path)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "5a4cf952",
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "cbf4462f",
            "metadata": {},
            "outputs": [],
            "source": [
                "train_subset = {\n",
                "    k: v\n",
                "    for k, v in parsed_data.items()\n",
                "    if v.get(\"draft_time\", datetime.date(1999, 9, 9)) < test_split_cutoff\n",
                "}\n",
                "val_subset = {\n",
                "    k: v\n",
                "    for k, v in parsed_data.items()\n",
                "    if v.get(\"draft_time\", datetime.date(1999, 9, 9)) >= test_split_cutoff\n",
                "}\n",
                "\n",
                "train_draft_dataset = datasets.DraftDataset(train_subset, recent_game_cutoff)\n",
                "val_draft_dataset = datasets.DraftDataset(val_subset, test_split_cutoff, use_all=True)\n",
                "\n",
                "small = set(list(train_subset.keys())[:500])\n",
                "check_draft_dataset = datasets.DraftDataset({k: v for k, v in train_subset.items() \n",
                "                                             if k in small}, recent_game_cutoff)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "1b938856",
            "metadata": {},
            "outputs": [],
            "source": [
                "len(val_subset), len(train_subset)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "0004d12a",
            "metadata": {},
            "outputs": [],
            "source": [
                "len(parsed_data)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "45979a8e",
            "metadata": {},
            "outputs": [],
            "source": [
                "data_out = []\n",
                "for draft_id, draft in train_subset.items():\n",
                "    sub_data = {\n",
                "        \"rank\": draft[\"rank\"] if draft[\"rank\"] else \"NA\",\n",
                "        \"event_match_wins\": draft[\"event_match_wins\"],\n",
                "        \"user_game_win_rate_bucket\": draft[\"user_game_win_rate_bucket\"],\n",
                "        \"draft_time\": draft[\"draft_time\"],\n",
                "    }\n",
                "    for round_num in range(len(draft[\"pick_data\"])):\n",
                "        weights = train_draft_dataset.get_weights(draft, round_num)\n",
                "        cp = deepcopy(sub_data)\n",
                "        cp[\"w1\"] = weights[0]\n",
                "        cp[\"w2\"] = weights[1]\n",
                "        cp[\"round\"] = round_num\n",
                "        data_out.append(cp)\n",
                "    if len(data_out) > 10000:\n",
                "        break\n",
                "df_out = pd.DataFrame(data_out)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "57845e72",
            "metadata": {},
            "outputs": [],
            "source": [
                "df_out.head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "d5cee314",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Generate scatterplot of example weights\n",
                "# px.scatter(\n",
                "#     df_out,\n",
                "#     x=\"round\",\n",
                "#     y=\"w1\",\n",
                "#     color=\"rank\",\n",
                "#     hover_data=[\"user_game_win_rate_bucket\", \"event_match_wins\"],\n",
                "#     category_orders={\"rank\": [\"mythic\", \"diamond\", \"platinum\", \"gold\", \"silver\", \"NA\"]},\n",
                "#     color_discrete_sequence=[\"orange\", \"teal\", \"green\", \"yellow\", \"silver\", \"black\"],\n",
                "# )"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "a15a6d29",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Generate scatterplot of win-rate weights and plot time of draft\n",
                "# px.scatter(\n",
                "#     df_out,\n",
                "#     x=\"round\",\n",
                "#     y=\"w2\",\n",
                "#     color=\"rank\",\n",
                "#     hover_data=[\"user_game_win_rate_bucket\", \"event_match_wins\"],\n",
                "#     category_orders={\"rank\": [\"mythic\", \"diamond\", \"platinum\", \"gold\", \"silver\", \"NA\"]},\n",
                "#     color_discrete_sequence=[\"orange\", \"teal\", \"green\", \"yellow\", \"silver\", \"black\"],\n",
                "# )\n",
                "# px.histogram(df_out, x=\"draft_time\", cumulative=True, histnorm=\"percent\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "11257b06",
            "metadata": {
                "scrolled": false
            },
            "outputs": [],
            "source": [
                "# load the model and ensure its forward method works\n",
                "params = {\n",
                "    \"n_cards\": 500,\n",
                "    \"emb_dim\": 512,\n",
                "    \"n_cards_in_pack\": 16,\n",
                "    \"n_steps\": 10000,\n",
                "}\n",
                "model = models.DraftTransformer(\n",
                "    **params,\n",
                ").to(\"cuda:0\")\n",
                "print(\n",
                "    model(\n",
                "        models.collate_batch([next(iter(train_draft_dataset))], device=\"cuda:0\"),\n",
                "    )\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "80efdbba",
            "metadata": {
                "scrolled": false
            },
            "outputs": [],
            "source": [
                "try:\n",
                "    mlflow.end_run()\n",
                "except Exception as e:\n",
                "    pass\n",
                "mlflow.start_run()\n",
                "mlflow.log_params({k: str(v) for k, v in params.items()})\n",
                "\n",
                "checkpoint = pl.callbacks.ModelCheckpoint(save_weights_only=True, filename=\"model\")\n",
                "trainer = pl.Trainer(\n",
                "    gpus=[0],\n",
                "    max_steps=model.n_steps,\n",
                "    #     profiler=\"simple\",\n",
                "    precision=16,\n",
                "    callbacks=[checkpoint],\n",
                "    #     benchmark=True,\n",
                "    check_val_every_n_epoch=2,\n",
                "    limit_val_batches=0.2,\n",
                ")\n",
                "\n",
                "\n",
                "train_dl = torch.utils.data.DataLoader(\n",
                "    train_draft_dataset,\n",
                "    batch_size=200,\n",
                "    shuffle=True,\n",
                "    drop_last=True,\n",
                "    collate_fn=models.collate_batch,\n",
                "    num_workers=2,\n",
                "    pin_memory=False,\n",
                ")\n",
                "val_dl = torch.utils.data.DataLoader(\n",
                "    val_draft_dataset,\n",
                "    batch_size=200,\n",
                "    shuffle=False,\n",
                "    drop_last=False,\n",
                "    collate_fn=models.collate_batch,\n",
                "    num_workers=2,\n",
                "    pin_memory=False,\n",
                ")\n",
                "\n",
                "\n",
                "trainer.fit(model, train_dl, val_dl)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "6fa90c91",
            "metadata": {
                "scrolled": false
            },
            "outputs": [],
            "source": [
                "dp = checkpoint.dirpath\n",
                "fn = os.listdir(trainer.checkpoint_callback.dirpath)[0]\n",
                "checkpoint_path = os.path.join(dp, fn)\n",
                "\n",
                "# log our model weights\n",
                "mlflow.log_artifact(checkpoint_path)\n",
                "\n",
                "# log the card ids\n",
                "card_id_path = f\"{dp}/card_ids.json\"\n",
                "with open(card_id_path, \"w\") as f:\n",
                "    json.dump(card_ids, f)\n",
                "\n",
                "mlflow.log_artifact(card_id_path)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "fc23cdc9",
            "metadata": {},
            "outputs": [],
            "source": [
                "model.metrics[\"train_accuracy_round_00\"]."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "48105429",
            "metadata": {},
            "outputs": [],
            "source": [
                "val_iter = iter(val_draft_dataset)\n",
                "bt = [next(val_iter) for _ in range(10)]\n",
                "collated = models.collate_batch(bt, device=\"cpu\")\n",
                "model.eval()\n",
                "model.to(\"cpu\")\n",
                "pred_a, pred_b = model(collated)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "a5caee72",
            "metadata": {},
            "outputs": [],
            "source": [
                "collated[\"picks\"].shape, pred_a.shape, collated[\"pick_weights\"]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "3dd68a54",
            "metadata": {},
            "outputs": [],
            "source": [
                "acc(pred_a, collated[\"picks\"])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "66722c63",
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "\n",
                "# log the model params/config\n",
                "model_config_path = f\"{dp}/model_config.json\"\n",
                "with open(model_config_path, \"w\") as f:\n",
                "    json.dump(params, f)\n",
                "\n",
                "mlflow.log_artifact(model_config_path)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3 (ipykernel)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}