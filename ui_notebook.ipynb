{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e638d667",
   "metadata": {},
   "source": [
    "### Setup\n",
    "\n",
    "- pip install dash pandas lxml nb_black dash-bootstrap-components\n",
    "- download card_list.csv from 17Lands and save it in `data/` https://17lands-public.s3.amazonaws.com/analysis_data/cards/card_list.csv\n",
    "- start this jupyter notebook with `jupyter notebook` from this path\n",
    "- update the path to your log file (can be found in 17Lands client - may not be necessary)\n",
    "- go to `localhost:8050/` to see the app!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6c7324",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext nb_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f32644",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "import json\n",
    "import logging\n",
    "from typing import List, Sequence, Union, Optional, Dict, Any, Tuple\n",
    "import datetime\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "import plotly\n",
    "import dash\n",
    "from dash import dcc\n",
    "from dash import html\n",
    "import dash_bootstrap_components as dbc\n",
    "from dash.dependencies import Input, Output\n",
    "from dash import dash_table\n",
    "from dash.dash_table.Format import Format, Scheme\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "from flask import Flask\n",
    "\n",
    "from mtgradient.log_parsing.follower_logic import (\n",
    "    DashFollower,\n",
    "    ALSATrackerType,\n",
    "    ColorTrackerType,\n",
    "    get_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1414f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_card_ratings_df(\n",
    "    expansion: str,\n",
    "    start_date=\"2020-01-01\",\n",
    "    end_date: Optional[str] = None,\n",
    "    format_priority: List[str] = [\n",
    "        \"PremierDraft\",\n",
    "        \"QuickDraft\",\n",
    "        \"TradDraft\",\n",
    "        \"CompDraft\",\n",
    "    ],\n",
    "):\n",
    "    if end_date is None:\n",
    "        end_date = datetime.date.today().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    col_map = {\n",
    "        \"avg_seen\": \"alsa\",\n",
    "        \"avg_pick\": \"ata\",\n",
    "        \"opening_hand_win_rate\": \"oh wr\",\n",
    "        \"ever_drawn_win_rate\": \"gd wr\",\n",
    "        \"drawn_improvement_win_rate\": \"iwd\",\n",
    "    }\n",
    "    card_df = None\n",
    "    for format_str in format_priority:\n",
    "        format_url = f\"https://www.17lands.com/card_ratings/data?expansion={expansion.upper()}&format={format_str}&start_date={start_date}&end_date={end_date}\"\n",
    "        resp = requests.get(format_url)\n",
    "        try:\n",
    "            json_data = resp.json()\n",
    "            card_df = pd.DataFrame(json_data)\n",
    "        except (json.JSONDecodeError, ValueError) as e:\n",
    "            print(f\"failed fetching data for {format_url}\")\n",
    "            card_df = pd.DataFrame([])\n",
    "        if len(card_df) == 0:\n",
    "            print(\n",
    "                f\"failed to find data for {format_str} for {expansion} between {start_date} and {end_date}, trying next format.\"\n",
    "            )\n",
    "            time.sleep(1)  # try to be polite\n",
    "        else:\n",
    "            print(f\"fetched {card_df.shape[0]} rows for {expansion} {format_str}\")\n",
    "            break\n",
    "    return card_df.rename(columns=col_map)\n",
    "\n",
    "def read_data(\n",
    "    data_path: str,\n",
    "    supported_expansions: List[str] = [\"ZNR\", \"KHM\", \"STX\", \"AFR\", \"MID\", \"VOW\"],\n",
    "    card_ratings_kwargs: Dict[str, Any] = {},\n",
    "    refresh=True,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Programmatically pull the 17Lands card ratings and stack them. Also\n",
    "    load the card_id mapping and join it.\n",
    "    \n",
    "    See get_card_ratings_df() for options  that can be passed to card_ratings_kwargs\n",
    "    \"\"\"\n",
    "    if not refresh:\n",
    "        return pd.read_csv(\"data/card_ratings_data.csv\", index_col=\"id\")\n",
    "    card_ids_df = pd.read_csv(\n",
    "        os.path.join(data_path, \"card_list.csv\"),\n",
    "        usecols=[\n",
    "            \"id\",\n",
    "            \"expansion\",\n",
    "            \"name\",\n",
    "            \"rarity\",\n",
    "            \"color_identity\",\n",
    "            \"mana_value\",\n",
    "            \"types\",\n",
    "        ],\n",
    "    )\n",
    "    card_ids_df = card_ids_df[card_ids_df.expansion.isin(supported_expansions)]\n",
    "    card_ids_df = card_ids_df[[\"id\", \"expansion\", \"name\", \"types\"]]\n",
    "\n",
    "    ratings_df = None\n",
    "    for set_name in supported_expansions:\n",
    "        single_df = get_card_ratings_df(set_name, **card_ratings_kwargs)\n",
    "\n",
    "        single_df[\"expansion\"] = set_name.upper()\n",
    "        if ratings_df is None:\n",
    "            ratings_df = single_df\n",
    "        else:\n",
    "            ratings_df = ratings_df.append(single_df)\n",
    "        time.sleep(1) # try to be polite\n",
    "    ratings_df = ratings_df.rename(columns={k: k.lower() for k in ratings_df.columns})\n",
    "\n",
    "    joined = pd.merge(\n",
    "        ratings_df,\n",
    "        card_ids_df,\n",
    "        how=\"left\",\n",
    "        left_on=[\"name\", \"expansion\"],\n",
    "        right_on=[\"name\", \"expansion\"],\n",
    "        suffixes=[\"\", \"_y\"],\n",
    "    )\n",
    "    joined.to_csv(\"data/card_ratings_data.csv\", index=False)\n",
    "    return joined.set_index(\"id\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d409a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The first time you run, this needs to be True - in future runs, this will take extra time,\n",
    "# but setting to True will pull all the 17Lands data you need freshly each time.\n",
    "# setting to False will save time if you're okay with how recent your data is.\n",
    "REFRESH_DATA = False\n",
    "df = read_data(\"./data/\", refresh=REFRESH_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6dc0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# so you can see available column names\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249a463e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# number of seconds between refreshes. Needs to be long enough to fully parse your\n",
    "# .log file. If your file is huge, this could be an issue, and you may want to exit\n",
    "# and reload the game\n",
    "N_SECONDS = 10\n",
    "\n",
    "# threshold for (pick_num - ALSA) at which we consider a\n",
    "# card to be signifying some amount of \"openness\" of that\n",
    "# color in the draft\n",
    "LATE_ALSA_DIFF_THRESHOLD = 0.5\n",
    "\n",
    "# if we see cards that show up \"late\" that are multicolor,\n",
    "# how much should we weight this as an indicator that\n",
    "# each of their colors is open?\n",
    "MULTICOLOR_ALSA_DIFF_FACTOR = 0.5\n",
    "\n",
    "# this parameter should be 0, but can be set to larger values to\n",
    "# accommodate large logs. If you've played a lot and have many\n",
    "# MB of data in your log, you might be better off skipping\n",
    "# a lot of it. This will skip the first SEEK_TO bytes of your\n",
    "# log. SET AT YOUR OWN RISK\n",
    "\n",
    "# SEEK_TO = 32e6  skips 32MB\n",
    "# SEEK_TO = 5e6  # skips 5MB\n",
    "SEEK_TO = 0\n",
    "\n",
    "# This is the path to your log file. If you want to test it out, I recommend\n",
    "# saving a copy of one and editing it to have however many events you'd like\n",
    "logfile = os.path.join(\n",
    "    Path.home(),\n",
    "    r\"AppData\\LocalLow\\Wizards Of The Coast\\MTGA\\Player.log\",\n",
    ")\n",
    "\n",
    "print(f\"looking for logfile at: {logfile}\")\n",
    "\n",
    "\n",
    "# This may pop up a dialog the first time, I'm not sure.\n",
    "token = get_config()\n",
    "\n",
    "# This controls what displays. you can print(df) to see your column options\n",
    "useful_cols = [\n",
    "    \"name\",\n",
    "    \"color\",\n",
    "    \"types\",\n",
    "    \"rarity\",\n",
    "    \"alsa\",\n",
    "    \"ata\",\n",
    "    \"oh wr\",\n",
    "    \"gd wr\",\n",
    "    \"iwd\",\n",
    "]\n",
    "\n",
    "# this controls formatting of columns\n",
    "percentage_cols = [\"iwd\", \"oh wr\", \"gd wr\"]\n",
    "numeric_cols = [\"alsa\", \"ata\"]\n",
    "\n",
    "# allows you to override the CSS of the dash app\n",
    "external_stylesheets = [\"https://codepen.io/chriddyp/pen/bWLwgP.css\", dbc.themes.GRID]\n",
    "\n",
    "# modify this to change the cell styling in the tables\n",
    "cell_styling = {\"textAlign\": \"left\", \"padding\": \"5px\"}\n",
    "\n",
    "# making server explicit so that eventually a Follower object could\n",
    "# run separately and just post relevant events to an event API\n",
    "# flask_app = Flask(__name__)\n",
    "\n",
    "# the core of the app\n",
    "app = dash.Dash(\n",
    "    __name__,\n",
    "    #     server=flask_app,\n",
    "    #     url_base_pathname=\"/dash/\",\n",
    "    external_stylesheets=external_stylesheets,\n",
    ")\n",
    "app.layout = html.Div(\n",
    "    html.Div(\n",
    "        [\n",
    "            dbc.Container(\n",
    "                [\n",
    "                    dbc.Row(html.H4(\"Current Options\")),\n",
    "                    dbc.Row(html.Div(id=\"live-update-text\")),\n",
    "                    dbc.Row(html.Div(id=\"current-pick-table-holder\")),\n",
    "                    dbc.Row(html.H4(\"Draft Info\")),\n",
    "                    dbc.Row(html.Div(id=\"draft-tracking-info\")),\n",
    "                    dbc.Row(html.H4(\"Pool So Far\")),\n",
    "                    dbc.Row(html.Div(id=\"pool-table-holder\")),\n",
    "                ]\n",
    "            ),\n",
    "            dcc.Interval(\n",
    "                id=\"interval-component\",\n",
    "                interval=N_SECONDS * 1000,  # in milliseconds\n",
    "                n_intervals=0,\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "# init draft-level trackers that live outside the Follower\n",
    "local_alsa_tracker: ALSATrackerType = {}\n",
    "local_color_tracker: ColorTrackerType = {}\n",
    "\n",
    "\n",
    "def get_color_count_graph(inp_df: pd.DataFrame) -> plotly.graph_objects.Figure:\n",
    "    \"\"\"\n",
    "    Count the occurences of each \"color\" symbol in the card data's \"color\" column\n",
    "    in the pool of cards you've drafted so far.\n",
    "    \"\"\"\n",
    "    color_counts = (\n",
    "        inp_df.color.apply(lambda x: list(x) if isinstance(x, str) else [])\n",
    "        .explode()\n",
    "        .value_counts()\n",
    "        .reset_index()\n",
    "        .rename(columns={\"index\": \"Color\", \"color\": \"Count\"})\n",
    "    )\n",
    "    color_hexes = [\"#838383\", \"#26b569\", \"#f85656\", \"#aae0fa\", \"#fef2be\"]\n",
    "    missing_colors = [\n",
    "        c for c in (\"B\", \"G\", \"R\", \"U\", \"W\") if c not in color_counts.Color.values\n",
    "    ]\n",
    "    missing_df = pd.DataFrame(\n",
    "        [[c, 0] for c in missing_colors], columns=[\"Color\", \"Count\"]\n",
    "    )\n",
    "    color_counts.append(missing_df)\n",
    "    color_counts = color_counts.sort_values(\"Color\")\n",
    "\n",
    "    fig = go.Figure(\n",
    "        data=[\n",
    "            go.Bar(name=x[0], x=[x[0]], y=[x[1]], marker_color=color_hexes[i])\n",
    "            for i, x in enumerate(color_counts.values)\n",
    "        ],\n",
    "    )\n",
    "    fig.update_layout(\n",
    "        title={\n",
    "            \"text\": \"Card Color Counts\",\n",
    "            \"y\": 0.9,\n",
    "            \"x\": 0.5,\n",
    "            \"xanchor\": \"center\",\n",
    "            \"yanchor\": \"top\",\n",
    "        }\n",
    "    )\n",
    "    return fig\n",
    "\n",
    "\n",
    "def get_type_summary(inp_df: pd.DataFrame) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Get counts of the core card types and of the other keywords in your\n",
    "    pool of drafted cards so far.\n",
    "    \"\"\"\n",
    "    copied = inp_df.copy()\n",
    "    card_types = [\n",
    "        \"Land\",\n",
    "        \"Artifact\",\n",
    "        \"Creature\",\n",
    "        \"Enchantment\",\n",
    "        \"Planeswalker\",\n",
    "        \"Instant\",\n",
    "        \"Sorcery\",\n",
    "    ]\n",
    "    copied[\"keywords\"] = copied[\"types\"].apply(\n",
    "        lambda x: [t.strip() for t in x.split(\" \") if t.strip() not in (\"\", \"-\")]\n",
    "    )\n",
    "    vc = copied[\"keywords\"].explode().value_counts().reset_index()\n",
    "    main = (\n",
    "        vc[vc[\"index\"].apply(lambda x: x in card_types)]\n",
    "        .copy()\n",
    "        .rename(columns={\"index\": \"type\", \"keywords\": \"count\"})\n",
    "    )\n",
    "    other = (\n",
    "        vc[~vc[\"index\"].apply(lambda x: x in card_types)]\n",
    "        .copy()\n",
    "        .rename(columns={\"index\": \"keyword\", \"keywords\": \"count\"})\n",
    "    )\n",
    "    return main, other\n",
    "\n",
    "\n",
    "def get_draft_level_info(\n",
    "    alsa_tracker: ALSATrackerType, color_tracker: ColorTrackerType\n",
    "):\n",
    "    # handle the color tracking\n",
    "    color_df = pd.DataFrame(\n",
    "        [[k, v] for k, v in color_tracker.items()],\n",
    "        columns=[\"color\", \"cards passed to you\"],\n",
    "    ).sort_values(\"color\")\n",
    "\n",
    "    # handle the ALSA tracking\n",
    "    alsa_diff_sums = {\"B\": 0, \"G\": 0, \"R\": 0, \"U\": 0, \"W\": 0}\n",
    "    for key, alsa_diff_dict in alsa_tracker.items():\n",
    "        for inner_color, val in alsa_diff_dict.items():\n",
    "            alsa_diff_sums[inner_color] += np.sum(val)\n",
    "    alsa_df = pd.DataFrame(\n",
    "        [[k, v] for k, v in alsa_diff_sums.items()],\n",
    "        columns=[\"color\", \"ALSA difference sum\"],\n",
    "    )\n",
    "    return color_df, alsa_df\n",
    "\n",
    "\n",
    "def get_pool_summary(inp_df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Return all of the summary objects:\n",
    "      - color count graph\n",
    "      - type count df\n",
    "      - keyword count df\n",
    "    \"\"\"\n",
    "    color_count_graph = get_color_count_graph(inp_df)\n",
    "    main_type_sum, other_type_sum = get_type_summary(inp_df)\n",
    "    return color_count_graph, main_type_sum, other_type_sum\n",
    "\n",
    "\n",
    "def add_format_to_cols(col_dicts: List[Dict[str, Any]]):\n",
    "    for col_dict in col_dicts:\n",
    "        if col_dict[\"name\"] in percentage_cols:\n",
    "            col_dict[\"format\"] = Format(precision=1, scheme=Scheme.percentage)\n",
    "            col_dict[\"type\"] = \"numeric\"\n",
    "        if col_dict[\"name\"] in numeric_cols:\n",
    "            col_dict[\"format\"] = Format(precision=1, scheme=Scheme.fixed)\n",
    "            col_dict[\"type\"] = \"numeric\"\n",
    "    return col_dicts\n",
    "\n",
    "\n",
    "# every N seconds, our Interval fires, and we update most of the app\n",
    "# by parsing the log\n",
    "@app.callback(\n",
    "    Output(\"live-update-text\", \"children\"),\n",
    "    Output(\"current-pick-table-holder\", \"children\"),\n",
    "    Output(\"draft-tracking-info\", \"children\"),\n",
    "    Output(\"pool-table-holder\", \"children\"),\n",
    "    Input(\"interval-component\", \"n_intervals\"),\n",
    ")\n",
    "def update_metrics(n):\n",
    "    \"\"\"\n",
    "    Update the whole app by parsing the log file\n",
    "    \"\"\"\n",
    "    t0 = time.time()\n",
    "    # create a 17Lands client with the API interaction removed\n",
    "    # TODO: just fix __init__ to set these\n",
    "    follower = DashFollower(token, \"\")\n",
    "    follower.alsa_tracker = local_alsa_tracker\n",
    "    follower.color_tracker = local_color_tracker\n",
    "    follower.df = df\n",
    "    follower.late_alsa_diff_threshold = LATE_ALSA_DIFF_THRESHOLD\n",
    "    follower.multicolor_alsa_diff_factor = MULTICOLOR_ALSA_DIFF_FACTOR\n",
    "    # parse your whole log\n",
    "    r = follower.parse_log(logfile, follow=False, skip_bytes=SEEK_TO)\n",
    "    t1 = time.time()\n",
    "    print(f\"parsed file in {t1 - t0} seconds\")\n",
    "\n",
    "    color_df, alsa_df = get_draft_level_info(local_alsa_tracker, local_color_tracker)\n",
    "\n",
    "    style = {\"padding\": \"5px\", \"fontSize\": \"16px\"}\n",
    "    # get the cards available to be picked\n",
    "    picked_df = df.loc[getattr(follower, \"pick_options\", []), useful_cols].sort_values(\n",
    "        \"iwd\", ascending=False\n",
    "    )\n",
    "    # get the cards you've already drafted\n",
    "    pool_df = df.loc[getattr(follower, \"pool_card_ids\", []), useful_cols].sort_values(\n",
    "        \"iwd\", ascending=False\n",
    "    )\n",
    "    # turn them both into Table objects\n",
    "    picked_cols = [{\"name\": i, \"id\": i} for i in picked_df.columns]\n",
    "    add_format_to_cols(picked_cols)\n",
    "    pick_table = html.Div(\n",
    "        dash_table.DataTable(\n",
    "            id=\"pick_table\",\n",
    "            columns=picked_cols,\n",
    "            data=picked_df.to_dict(\"records\"),\n",
    "            style_cell=cell_styling,\n",
    "        ),\n",
    "        style={\"width\": \"80%\", \"margin\": \"auto\"},\n",
    "    )\n",
    "    pool_table = html.Div(\n",
    "        dash_table.DataTable(\n",
    "            id=\"pool_table\",\n",
    "            columns=add_format_to_cols([{\"name\": i, \"id\": i} for i in pool_df.columns]),\n",
    "            data=pool_df.to_dict(\"records\"),\n",
    "            style_cell=cell_styling,\n",
    "        )\n",
    "    )\n",
    "    # get the summary statistics for your pool\n",
    "    pool_summary, main_type_sum, other_type_sum = get_pool_summary(pool_df)\n",
    "    main_type_sum = dash_table.DataTable(\n",
    "        id=\"main_type_table\",\n",
    "        columns=[{\"name\": i, \"id\": i} for i in main_type_sum.columns],\n",
    "        data=main_type_sum.to_dict(\"records\"),\n",
    "        style_cell=cell_styling,\n",
    "    )\n",
    "    other_type_sum = dash_table.DataTable(\n",
    "        id=\"other_type_table\",\n",
    "        columns=[{\"name\": i, \"id\": i} for i in other_type_sum.columns],\n",
    "        data=other_type_sum.to_dict(\"records\"),\n",
    "        style_cell=cell_styling,\n",
    "    )\n",
    "    # update the container with the summary info\n",
    "    curr_div = dbc.Container(\n",
    "        dbc.Row(\n",
    "            [\n",
    "                dbc.Col(pool_table, width={\"size\": 8}),\n",
    "                dbc.Col(\n",
    "                    [\n",
    "                        dbc.Row(dcc.Graph(figure=pool_summary)),\n",
    "                        dbc.Row(main_type_sum),\n",
    "                        dbc.Row(html.Div(\"--\")),\n",
    "                        dbc.Row(other_type_sum),\n",
    "                    ],\n",
    "                    width={\"size\": 4},\n",
    "                ),\n",
    "            ]\n",
    "        )\n",
    "    )\n",
    "    draft_info_div = dbc.Container(\n",
    "        dbc.Row(\n",
    "            [\n",
    "                dbc.Col(\n",
    "                    dash_table.DataTable(\n",
    "                        columns=[{\"name\": i, \"id\": i} for i in color_df.columns],\n",
    "                        data=color_df.to_dict(\"records\"),\n",
    "                        style_cell=cell_styling,\n",
    "                    ),\n",
    "                    width={\"size\": 4},\n",
    "                ),\n",
    "                dbc.Col(\n",
    "                    dash_table.DataTable(\n",
    "                        columns=[{\"name\": i, \"id\": i} for i in alsa_df.columns],\n",
    "                        data=alsa_df.to_dict(\"records\"),\n",
    "                        style_cell=cell_styling,\n",
    "                    ),\n",
    "                    width={\"size\": 4},\n",
    "                ),\n",
    "            ]\n",
    "        )\n",
    "    )\n",
    "    print(f\"rebuilt dash components in {time.time() - t1} seconds\")\n",
    "    return [\n",
    "        html.Span(\n",
    "            f\"Pack {follower.pack_number}, Pick {follower.pick_number}\", style=style\n",
    "        ),\n",
    "        pick_table,\n",
    "        draft_info_div,\n",
    "        curr_div,\n",
    "    ]\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run_server()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a7c3c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
