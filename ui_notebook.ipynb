{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e638d667",
   "metadata": {},
   "source": [
    "### Setup\n",
    "\n",
    "- pip install dash pandas lxml nb_black dash-bootstrap-components\n",
    "- download card_list.csv from 17Lands and save it in `data/` https://17lands-public.s3.amazonaws.com/analysis_data/cards/card_list.csv\n",
    "- start this jupyter notebook with `jupyter notebook` from this path\n",
    "- update the path to your log file (can be found in 17Lands client - may not be necessary)\n",
    "- go to `localhost:8050/` to see the app!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b6c7324",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 1;\n",
       "                var nbb_unformatted_code = \"%load_ext nb_black\";\n",
       "                var nbb_formatted_code = \"%load_ext nb_black\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext nb_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05f32644",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2;\n",
       "                var nbb_unformatted_code = \"import requests\\nimport os\\nimport json\\nimport logging\\nfrom typing import List, Sequence, Union, Optional, Dict, Any, Tuple\\nimport datetime\\nimport time\\nimport json\\nfrom pathlib import Path\\n\\nimport plotly\\nimport dash\\nfrom dash import dcc\\nfrom dash import html\\nimport dash_bootstrap_components as dbc\\nfrom dash.dependencies import Input, Output\\nfrom dash import dash_table\\nfrom dash.dash_table.Format import Format, Scheme\\nimport pandas as pd\\nimport plotly.express as px\\nimport plotly.graph_objects as go\\nimport numpy as np\\nfrom flask import Flask\\n\\nfrom mtgradient.log_parsing.follower_logic import (\\n    DashFollower,\\n    ALSATrackerType,\\n    ColorTrackerType,\\n    get_config,\\n)\";\n",
       "                var nbb_formatted_code = \"import requests\\nimport os\\nimport json\\nimport logging\\nfrom typing import List, Sequence, Union, Optional, Dict, Any, Tuple\\nimport datetime\\nimport time\\nimport json\\nfrom pathlib import Path\\n\\nimport plotly\\nimport dash\\nfrom dash import dcc\\nfrom dash import html\\nimport dash_bootstrap_components as dbc\\nfrom dash.dependencies import Input, Output\\nfrom dash import dash_table\\nfrom dash.dash_table.Format import Format, Scheme\\nimport pandas as pd\\nimport plotly.express as px\\nimport plotly.graph_objects as go\\nimport numpy as np\\nfrom flask import Flask\\n\\nfrom mtgradient.log_parsing.follower_logic import (\\n    DashFollower,\\n    ALSATrackerType,\\n    ColorTrackerType,\\n    get_config,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import requests\n",
    "import os\n",
    "import json\n",
    "import logging\n",
    "from typing import List, Sequence, Union, Optional, Dict, Any, Tuple\n",
    "import datetime\n",
    "import time\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import plotly\n",
    "import dash\n",
    "from dash import dcc\n",
    "from dash import html\n",
    "import dash_bootstrap_components as dbc\n",
    "from dash.dependencies import Input, Output\n",
    "from dash import dash_table\n",
    "from dash.dash_table.Format import Format, Scheme\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "from flask import Flask\n",
    "\n",
    "from mtgradient.log_parsing.follower_logic import (\n",
    "    DashFollower,\n",
    "    ALSATrackerType,\n",
    "    ColorTrackerType,\n",
    "    get_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1414f1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 3;\n",
       "                var nbb_unformatted_code = \"def get_card_ratings_df(\\n    expansion: str,\\n    start_date=\\\"2020-01-01\\\",\\n    end_date: Optional[str] = None,\\n    format_priority: List[str] = [\\n        \\\"PremierDraft\\\",\\n        \\\"QuickDraft\\\",\\n        \\\"TradDraft\\\",\\n        \\\"CompDraft\\\",\\n    ],\\n):\\n    if end_date is None:\\n        end_date = datetime.date.today().strftime(\\\"%Y-%m-%d\\\")\\n\\n    col_map = {\\n        \\\"avg_seen\\\": \\\"alsa\\\",\\n        \\\"avg_pick\\\": \\\"ata\\\",\\n        \\\"opening_hand_win_rate\\\": \\\"oh wr\\\",\\n        \\\"ever_drawn_win_rate\\\": \\\"gd wr\\\",\\n        \\\"drawn_improvement_win_rate\\\": \\\"iwd\\\",\\n    }\\n    card_df = None\\n    for format_str in format_priority:\\n        format_url = f\\\"https://www.17lands.com/card_ratings/data?expansion={expansion.upper()}&format={format_str}&start_date={start_date}&end_date={end_date}\\\"\\n        resp = requests.get(format_url)\\n        try:\\n            json_data = resp.json()\\n            card_df = pd.DataFrame(json_data)\\n        except (json.JSONDecodeError, ValueError) as e:\\n            print(f\\\"failed fetching data for {format_url}\\\")\\n            card_df = pd.DataFrame([])\\n        if len(card_df) == 0:\\n            print(\\n                f\\\"failed to find data for {format_str} for {expansion} between {start_date} and {end_date}, trying next format.\\\"\\n            )\\n            time.sleep(1)  # try to be polite\\n        else:\\n            print(f\\\"fetched {card_df.shape[0]} rows for {expansion} {format_str}\\\")\\n            break\\n    return card_df.rename(columns=col_map)\\n\\n\\ndef read_data(\\n    data_path: str,\\n    supported_expansions: List[str] = [\\n        \\\"ZNR\\\",\\n        \\\"KHM\\\",\\n        \\\"STX\\\",\\n        \\\"AFR\\\",\\n        \\\"MID\\\",\\n        \\\"VOW\\\",\\n        \\\"NEO\\\",\\n        \\\"SNC\\\",\\n        \\\"HBG\\\",\\n    ],\\n    card_ratings_kwargs: Dict[str, Any] = {},\\n    refresh=True,\\n) -> pd.DataFrame:\\n    \\\"\\\"\\\"\\n    Programmatically pull the 17Lands card ratings and stack them. Also\\n    load the card_id mapping and join it.\\n\\n    See get_card_ratings_df() for options  that can be passed to card_ratings_kwargs\\n    \\\"\\\"\\\"\\n    if not refresh:\\n        return pd.read_csv(f\\\"{data_path}/card_ratings_data.csv\\\", index_col=\\\"id\\\")\\n    card_ids_df = pd.read_csv(\\n        os.path.join(data_path, \\\"card_list.csv\\\"),\\n        usecols=[\\n            \\\"id\\\",\\n            \\\"expansion\\\",\\n            \\\"name\\\",\\n            \\\"rarity\\\",\\n            \\\"color_identity\\\",\\n            \\\"mana_value\\\",\\n            \\\"types\\\",\\n        ],\\n    )\\n    card_ids_df = card_ids_df[card_ids_df.expansion.isin(supported_expansions)]\\n    card_ids_df = card_ids_df[[\\\"id\\\", \\\"expansion\\\", \\\"name\\\", \\\"types\\\"]]\\n\\n    ratings_df = None\\n    for set_name in supported_expansions:\\n        single_df = get_card_ratings_df(set_name, **card_ratings_kwargs)\\n\\n        single_df[\\\"expansion\\\"] = set_name.upper()\\n        if ratings_df is None:\\n            ratings_df = single_df\\n        else:\\n            ratings_df = pd.concat([ratings_df, single_df])\\n        time.sleep(1)  # try to be polite\\n    ratings_df = ratings_df.rename(columns={k: k.lower() for k in ratings_df.columns})\\n\\n    joined = pd.merge(\\n        ratings_df,\\n        card_ids_df,\\n        how=\\\"left\\\",\\n        left_on=[\\\"name\\\", \\\"expansion\\\"],\\n        right_on=[\\\"name\\\", \\\"expansion\\\"],\\n        suffixes=[\\\"\\\", \\\"_y\\\"],\\n    )\\n    joined.to_csv(f\\\"{data_path}/card_ratings_data.csv\\\", index=False)\\n    return joined.set_index(\\\"id\\\")\\n\\n\\nmodel = None\";\n",
       "                var nbb_formatted_code = \"def get_card_ratings_df(\\n    expansion: str,\\n    start_date=\\\"2020-01-01\\\",\\n    end_date: Optional[str] = None,\\n    format_priority: List[str] = [\\n        \\\"PremierDraft\\\",\\n        \\\"QuickDraft\\\",\\n        \\\"TradDraft\\\",\\n        \\\"CompDraft\\\",\\n    ],\\n):\\n    if end_date is None:\\n        end_date = datetime.date.today().strftime(\\\"%Y-%m-%d\\\")\\n\\n    col_map = {\\n        \\\"avg_seen\\\": \\\"alsa\\\",\\n        \\\"avg_pick\\\": \\\"ata\\\",\\n        \\\"opening_hand_win_rate\\\": \\\"oh wr\\\",\\n        \\\"ever_drawn_win_rate\\\": \\\"gd wr\\\",\\n        \\\"drawn_improvement_win_rate\\\": \\\"iwd\\\",\\n    }\\n    card_df = None\\n    for format_str in format_priority:\\n        format_url = f\\\"https://www.17lands.com/card_ratings/data?expansion={expansion.upper()}&format={format_str}&start_date={start_date}&end_date={end_date}\\\"\\n        resp = requests.get(format_url)\\n        try:\\n            json_data = resp.json()\\n            card_df = pd.DataFrame(json_data)\\n        except (json.JSONDecodeError, ValueError) as e:\\n            print(f\\\"failed fetching data for {format_url}\\\")\\n            card_df = pd.DataFrame([])\\n        if len(card_df) == 0:\\n            print(\\n                f\\\"failed to find data for {format_str} for {expansion} between {start_date} and {end_date}, trying next format.\\\"\\n            )\\n            time.sleep(1)  # try to be polite\\n        else:\\n            print(f\\\"fetched {card_df.shape[0]} rows for {expansion} {format_str}\\\")\\n            break\\n    return card_df.rename(columns=col_map)\\n\\n\\ndef read_data(\\n    data_path: str,\\n    supported_expansions: List[str] = [\\n        \\\"ZNR\\\",\\n        \\\"KHM\\\",\\n        \\\"STX\\\",\\n        \\\"AFR\\\",\\n        \\\"MID\\\",\\n        \\\"VOW\\\",\\n        \\\"NEO\\\",\\n        \\\"SNC\\\",\\n        \\\"HBG\\\",\\n    ],\\n    card_ratings_kwargs: Dict[str, Any] = {},\\n    refresh=True,\\n) -> pd.DataFrame:\\n    \\\"\\\"\\\"\\n    Programmatically pull the 17Lands card ratings and stack them. Also\\n    load the card_id mapping and join it.\\n\\n    See get_card_ratings_df() for options  that can be passed to card_ratings_kwargs\\n    \\\"\\\"\\\"\\n    if not refresh:\\n        return pd.read_csv(f\\\"{data_path}/card_ratings_data.csv\\\", index_col=\\\"id\\\")\\n    card_ids_df = pd.read_csv(\\n        os.path.join(data_path, \\\"card_list.csv\\\"),\\n        usecols=[\\n            \\\"id\\\",\\n            \\\"expansion\\\",\\n            \\\"name\\\",\\n            \\\"rarity\\\",\\n            \\\"color_identity\\\",\\n            \\\"mana_value\\\",\\n            \\\"types\\\",\\n        ],\\n    )\\n    card_ids_df = card_ids_df[card_ids_df.expansion.isin(supported_expansions)]\\n    card_ids_df = card_ids_df[[\\\"id\\\", \\\"expansion\\\", \\\"name\\\", \\\"types\\\"]]\\n\\n    ratings_df = None\\n    for set_name in supported_expansions:\\n        single_df = get_card_ratings_df(set_name, **card_ratings_kwargs)\\n\\n        single_df[\\\"expansion\\\"] = set_name.upper()\\n        if ratings_df is None:\\n            ratings_df = single_df\\n        else:\\n            ratings_df = pd.concat([ratings_df, single_df])\\n        time.sleep(1)  # try to be polite\\n    ratings_df = ratings_df.rename(columns={k: k.lower() for k in ratings_df.columns})\\n\\n    joined = pd.merge(\\n        ratings_df,\\n        card_ids_df,\\n        how=\\\"left\\\",\\n        left_on=[\\\"name\\\", \\\"expansion\\\"],\\n        right_on=[\\\"name\\\", \\\"expansion\\\"],\\n        suffixes=[\\\"\\\", \\\"_y\\\"],\\n    )\\n    joined.to_csv(f\\\"{data_path}/card_ratings_data.csv\\\", index=False)\\n    return joined.set_index(\\\"id\\\")\\n\\n\\nmodel = None\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_card_ratings_df(\n",
    "    expansion: str,\n",
    "    start_date=\"2020-01-01\",\n",
    "    end_date: Optional[str] = None,\n",
    "    format_priority: List[str] = [\n",
    "        \"PremierDraft\",\n",
    "        \"QuickDraft\",\n",
    "        \"TradDraft\",\n",
    "        \"CompDraft\",\n",
    "    ],\n",
    "):\n",
    "    if end_date is None:\n",
    "        end_date = datetime.date.today().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    col_map = {\n",
    "        \"avg_seen\": \"alsa\",\n",
    "        \"avg_pick\": \"ata\",\n",
    "        \"opening_hand_win_rate\": \"oh wr\",\n",
    "        \"ever_drawn_win_rate\": \"gd wr\",\n",
    "        \"drawn_improvement_win_rate\": \"iwd\",\n",
    "    }\n",
    "    card_df = None\n",
    "    for format_str in format_priority:\n",
    "        format_url = f\"https://www.17lands.com/card_ratings/data?expansion={expansion.upper()}&format={format_str}&start_date={start_date}&end_date={end_date}\"\n",
    "        resp = requests.get(format_url)\n",
    "        try:\n",
    "            json_data = resp.json()\n",
    "            card_df = pd.DataFrame(json_data)\n",
    "        except (json.JSONDecodeError, ValueError) as e:\n",
    "            print(f\"failed fetching data for {format_url}\")\n",
    "            card_df = pd.DataFrame([])\n",
    "        if len(card_df) == 0:\n",
    "            print(\n",
    "                f\"failed to find data for {format_str} for {expansion} between {start_date} and {end_date}, trying next format.\"\n",
    "            )\n",
    "            time.sleep(1)  # try to be polite\n",
    "        else:\n",
    "            print(f\"fetched {card_df.shape[0]} rows for {expansion} {format_str}\")\n",
    "            break\n",
    "    return card_df.rename(columns=col_map)\n",
    "\n",
    "\n",
    "def read_data(\n",
    "    data_path: str,\n",
    "    supported_expansions: List[str] = [\n",
    "        \"ZNR\",\n",
    "        \"KHM\",\n",
    "        \"STX\",\n",
    "        \"AFR\",\n",
    "        \"MID\",\n",
    "        \"VOW\",\n",
    "        \"NEO\",\n",
    "        \"SNC\",\n",
    "        \"HBG\",\n",
    "    ],\n",
    "    card_ratings_kwargs: Dict[str, Any] = {},\n",
    "    refresh=True,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Programmatically pull the 17Lands card ratings and stack them. Also\n",
    "    load the card_id mapping and join it.\n",
    "\n",
    "    See get_card_ratings_df() for options  that can be passed to card_ratings_kwargs\n",
    "    \"\"\"\n",
    "    if not refresh:\n",
    "        return pd.read_csv(f\"{data_path}/card_ratings_data.csv\", index_col=\"id\")\n",
    "    card_ids_df = pd.read_csv(\n",
    "        os.path.join(data_path, \"card_list.csv\"),\n",
    "        usecols=[\n",
    "            \"id\",\n",
    "            \"expansion\",\n",
    "            \"name\",\n",
    "            \"rarity\",\n",
    "            \"color_identity\",\n",
    "            \"mana_value\",\n",
    "            \"types\",\n",
    "        ],\n",
    "    )\n",
    "    card_ids_df = card_ids_df[card_ids_df.expansion.isin(supported_expansions)]\n",
    "    card_ids_df = card_ids_df[[\"id\", \"expansion\", \"name\", \"types\"]]\n",
    "\n",
    "    ratings_df = None\n",
    "    for set_name in supported_expansions:\n",
    "        single_df = get_card_ratings_df(set_name, **card_ratings_kwargs)\n",
    "\n",
    "        single_df[\"expansion\"] = set_name.upper()\n",
    "        if ratings_df is None:\n",
    "            ratings_df = single_df\n",
    "        else:\n",
    "            ratings_df = pd.concat([ratings_df, single_df])\n",
    "        time.sleep(1)  # try to be polite\n",
    "    ratings_df = ratings_df.rename(columns={k: k.lower() for k in ratings_df.columns})\n",
    "\n",
    "    joined = pd.merge(\n",
    "        ratings_df,\n",
    "        card_ids_df,\n",
    "        how=\"left\",\n",
    "        left_on=[\"name\", \"expansion\"],\n",
    "        right_on=[\"name\", \"expansion\"],\n",
    "        suffixes=[\"\", \"_y\"],\n",
    "    )\n",
    "    joined.to_csv(f\"{data_path}/card_ratings_data.csv\", index=False)\n",
    "    return joined.set_index(\"id\")\n",
    "\n",
    "\n",
    "model = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "504fea6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 4;\n",
       "                var nbb_unformatted_code = \"# WIP: code for loading drafting bot\\nfrom mtgradient.models import DraftTransformer, collate_batch\\n\\nset_name = \\\"NEO\\\"\\nmodel_path = os.path.join(\\\"artifacts\\\", set_name)\\nmodel = DraftTransformer.load_from_checkpoint(\\n    os.path.join(model_path, \\\"model.ckpt\\\"), n_cards=300, emb_dim=512, n_cards_in_pack=15\\n)\\nwith open(os.path.join(model_path, \\\"card_ids.json\\\"), \\\"r\\\") as f:\\n    card_ids = json.load(f)\";\n",
       "                var nbb_formatted_code = \"# WIP: code for loading drafting bot\\nfrom mtgradient.models import DraftTransformer, collate_batch\\n\\nset_name = \\\"NEO\\\"\\nmodel_path = os.path.join(\\\"artifacts\\\", set_name)\\nmodel = DraftTransformer.load_from_checkpoint(\\n    os.path.join(model_path, \\\"model.ckpt\\\"), n_cards=300, emb_dim=512, n_cards_in_pack=15\\n)\\nwith open(os.path.join(model_path, \\\"card_ids.json\\\"), \\\"r\\\") as f:\\n    card_ids = json.load(f)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# WIP: code for loading drafting bot\n",
    "from mtgradient.models import DraftTransformer, collate_batch\n",
    "\n",
    "set_name = \"NEO\"\n",
    "model_path = os.path.join(\"artifacts\", set_name)\n",
    "model = DraftTransformer.load_from_checkpoint(\n",
    "    os.path.join(model_path, \"model.ckpt\"), n_cards=300, emb_dim=512, n_cards_in_pack=15\n",
    ")\n",
    "with open(os.path.join(model_path, \"card_ids.json\"), \"r\") as f:\n",
    "    card_ids = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82d409a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 5;\n",
       "                var nbb_unformatted_code = \"# The first time you run, this needs to be True - in future runs, this will take extra time,\\n# but setting to True will pull all the 17Lands data you need freshly each time.\\n# setting to False will save time if you're okay with how recent your data is.\\nREFRESH_DATA = False\\ndf = read_data(\\\"./artifacts/\\\", refresh=REFRESH_DATA)\";\n",
       "                var nbb_formatted_code = \"# The first time you run, this needs to be True - in future runs, this will take extra time,\\n# but setting to True will pull all the 17Lands data you need freshly each time.\\n# setting to False will save time if you're okay with how recent your data is.\\nREFRESH_DATA = False\\ndf = read_data(\\\"./artifacts/\\\", refresh=REFRESH_DATA)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# The first time you run, this needs to be True - in future runs, this will take extra time,\n",
    "# but setting to True will pull all the 17Lands data you need freshly each time.\n",
    "# setting to False will save time if you're okay with how recent your data is.\n",
    "REFRESH_DATA = False\n",
    "df = read_data(\"./artifacts/\", refresh=REFRESH_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d6dc0c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seen_count</th>\n",
       "      <th>alsa</th>\n",
       "      <th>pick_count</th>\n",
       "      <th>ata</th>\n",
       "      <th>game_count</th>\n",
       "      <th>win_rate</th>\n",
       "      <th>sideboard_game_count</th>\n",
       "      <th>sideboard_win_rate</th>\n",
       "      <th>opening_hand_game_count</th>\n",
       "      <th>oh wr</th>\n",
       "      <th>...</th>\n",
       "      <th>never_drawn_game_count</th>\n",
       "      <th>never_drawn_win_rate</th>\n",
       "      <th>iwd</th>\n",
       "      <th>name</th>\n",
       "      <th>color</th>\n",
       "      <th>rarity</th>\n",
       "      <th>url</th>\n",
       "      <th>url_back</th>\n",
       "      <th>expansion</th>\n",
       "      <th>types</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>73183.0</th>\n",
       "      <td>28159</td>\n",
       "      <td>6.598104</td>\n",
       "      <td>3868</td>\n",
       "      <td>9.298862</td>\n",
       "      <td>6419</td>\n",
       "      <td>0.535909</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>805</td>\n",
       "      <td>0.546584</td>\n",
       "      <td>...</td>\n",
       "      <td>2630</td>\n",
       "      <td>0.551711</td>\n",
       "      <td>-0.021780</td>\n",
       "      <td>Allied Assault</td>\n",
       "      <td>W</td>\n",
       "      <td>uncommon</td>\n",
       "      <td>https://c1.scryfall.com/file/scryfall-cards/bo...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ZNR</td>\n",
       "      <td>Instant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73184.0</th>\n",
       "      <td>1129</td>\n",
       "      <td>1.544730</td>\n",
       "      <td>710</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>3007</td>\n",
       "      <td>0.549385</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>332</td>\n",
       "      <td>0.569277</td>\n",
       "      <td>...</td>\n",
       "      <td>1265</td>\n",
       "      <td>0.520949</td>\n",
       "      <td>0.066957</td>\n",
       "      <td>Angel of Destiny</td>\n",
       "      <td>W</td>\n",
       "      <td>mythic</td>\n",
       "      <td>https://c1.scryfall.com/file/scryfall-cards/bo...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ZNR</td>\n",
       "      <td>Creature - Angel Cleric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73185.0</th>\n",
       "      <td>74747</td>\n",
       "      <td>6.100218</td>\n",
       "      <td>10550</td>\n",
       "      <td>8.612322</td>\n",
       "      <td>27054</td>\n",
       "      <td>0.535669</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4379</td>\n",
       "      <td>0.516785</td>\n",
       "      <td>...</td>\n",
       "      <td>10589</td>\n",
       "      <td>0.543961</td>\n",
       "      <td>-0.017694</td>\n",
       "      <td>Angelheart Protector</td>\n",
       "      <td>W</td>\n",
       "      <td>common</td>\n",
       "      <td>https://c1.scryfall.com/file/scryfall-cards/bo...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ZNR</td>\n",
       "      <td>Creature - Human Cleric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73186.0</th>\n",
       "      <td>4402</td>\n",
       "      <td>3.088596</td>\n",
       "      <td>869</td>\n",
       "      <td>3.756041</td>\n",
       "      <td>2621</td>\n",
       "      <td>0.515834</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>314</td>\n",
       "      <td>0.480892</td>\n",
       "      <td>...</td>\n",
       "      <td>1059</td>\n",
       "      <td>0.503305</td>\n",
       "      <td>0.007894</td>\n",
       "      <td>Archon of Emeria</td>\n",
       "      <td>W</td>\n",
       "      <td>rare</td>\n",
       "      <td>https://c1.scryfall.com/file/scryfall-cards/bo...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ZNR</td>\n",
       "      <td>Creature - Archon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73187.0</th>\n",
       "      <td>3598</td>\n",
       "      <td>2.497499</td>\n",
       "      <td>1237</td>\n",
       "      <td>2.767179</td>\n",
       "      <td>5170</td>\n",
       "      <td>0.552031</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>729</td>\n",
       "      <td>0.615912</td>\n",
       "      <td>...</td>\n",
       "      <td>2238</td>\n",
       "      <td>0.542449</td>\n",
       "      <td>0.043306</td>\n",
       "      <td>Archpriest of Iona</td>\n",
       "      <td>W</td>\n",
       "      <td>rare</td>\n",
       "      <td>https://c1.scryfall.com/file/scryfall-cards/bo...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ZNR</td>\n",
       "      <td>Creature - Human Cleric</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         seen_count      alsa  pick_count       ata  game_count  win_rate  \\\n",
       "id                                                                          \n",
       "73183.0       28159  6.598104        3868  9.298862        6419  0.535909   \n",
       "73184.0        1129  1.544730         710  1.500000        3007  0.549385   \n",
       "73185.0       74747  6.100218       10550  8.612322       27054  0.535669   \n",
       "73186.0        4402  3.088596         869  3.756041        2621  0.515834   \n",
       "73187.0        3598  2.497499        1237  2.767179        5170  0.552031   \n",
       "\n",
       "         sideboard_game_count  sideboard_win_rate  opening_hand_game_count  \\\n",
       "id                                                                           \n",
       "73183.0                     0                 NaN                      805   \n",
       "73184.0                     0                 NaN                      332   \n",
       "73185.0                     0                 NaN                     4379   \n",
       "73186.0                     0                 NaN                      314   \n",
       "73187.0                     0                 NaN                      729   \n",
       "\n",
       "            oh wr  ...  never_drawn_game_count  never_drawn_win_rate  \\\n",
       "id                 ...                                                 \n",
       "73183.0  0.546584  ...                    2630              0.551711   \n",
       "73184.0  0.569277  ...                    1265              0.520949   \n",
       "73185.0  0.516785  ...                   10589              0.543961   \n",
       "73186.0  0.480892  ...                    1059              0.503305   \n",
       "73187.0  0.615912  ...                    2238              0.542449   \n",
       "\n",
       "              iwd                  name  color    rarity  \\\n",
       "id                                                         \n",
       "73183.0 -0.021780        Allied Assault      W  uncommon   \n",
       "73184.0  0.066957      Angel of Destiny      W    mythic   \n",
       "73185.0 -0.017694  Angelheart Protector      W    common   \n",
       "73186.0  0.007894      Archon of Emeria      W      rare   \n",
       "73187.0  0.043306    Archpriest of Iona      W      rare   \n",
       "\n",
       "                                                       url url_back expansion  \\\n",
       "id                                                                              \n",
       "73183.0  https://c1.scryfall.com/file/scryfall-cards/bo...      NaN       ZNR   \n",
       "73184.0  https://c1.scryfall.com/file/scryfall-cards/bo...      NaN       ZNR   \n",
       "73185.0  https://c1.scryfall.com/file/scryfall-cards/bo...      NaN       ZNR   \n",
       "73186.0  https://c1.scryfall.com/file/scryfall-cards/bo...      NaN       ZNR   \n",
       "73187.0  https://c1.scryfall.com/file/scryfall-cards/bo...      NaN       ZNR   \n",
       "\n",
       "                           types  \n",
       "id                                \n",
       "73183.0                  Instant  \n",
       "73184.0  Creature - Angel Cleric  \n",
       "73185.0  Creature - Human Cleric  \n",
       "73186.0        Creature - Archon  \n",
       "73187.0  Creature - Human Cleric  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 6;\n",
       "                var nbb_unformatted_code = \"# so you can see available column names\\ndf.head(5)\";\n",
       "                var nbb_formatted_code = \"# so you can see available column names\\ndf.head(5)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# so you can see available column names\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "249a463e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "looking for logfile at: C:\\Users\\thisi\\AppData\\LocalLow\\Wizards Of The Coast\\MTGA\\Player.log\n",
      "Dash is running on http://127.0.0.1:8050/\n",
      "\n",
      " * Serving Flask app '__main__' (lazy loading)\n",
      " * Environment: production\n",
      "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
      "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://127.0.0.1:8050/ (Press CTRL+C to quit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parsed file in 0.030762910842895508 seconds\n",
      "[82, 209, 134, 80, 239, 162, 106, 271, 25, 155, 297, 170]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thisi\\AppData\\Local\\Temp/ipykernel_4992/3068334890.py:121: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  color_counts.append(missing_df)\n",
      "127.0.0.1 - - [09/Aug/2022 10:55:54] \"POST /_dash-update-component HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rebuilt dash components in 0.7321903705596924 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thisi\\AppData\\Local\\Temp/ipykernel_4992/3068334890.py:121: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n",
      "127.0.0.1 - - [09/Aug/2022 10:56:01] \"POST /_dash-update-component HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parsed file in 0.02502274513244629 seconds\n",
      "[82, 209, 134, 80, 239, 162, 106, 271, 25, 155, 297, 170]\n",
      "rebuilt dash components in 0.12211084365844727 seconds\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 7;\n",
       "                var nbb_unformatted_code = \"# number of seconds between refreshes. Needs to be long enough to fully parse your\\n# .log file. If your file is huge, this could be an issue, and you may want to exit\\n# and reload the game\\nN_SECONDS = 10\\n\\n# threshold for (pick_num - ALSA) at which we consider a\\n# card to be signifying some amount of \\\"openness\\\" of that\\n# color in the draft\\nLATE_ALSA_DIFF_THRESHOLD = 0.5\\n\\n# if we see cards that show up \\\"late\\\" that are multicolor,\\n# how much should we weight this as an indicator that\\n# each of their colors is open?\\nMULTICOLOR_ALSA_DIFF_FACTOR = 0.5\\n\\n# this parameter should be 0, but can be set to larger values to\\n# accommodate large logs. If you've played a lot and have many\\n# MB of data in your log, you might be better off skipping\\n# a lot of it. This will skip the first SEEK_TO bytes of your\\n# log. SET AT YOUR OWN RISK\\n\\n# SEEK_TO = 32e6  skips 32MB\\n# SEEK_TO = 5e6  # skips 5MB\\nSEEK_TO = 0\\n\\n# This is the path to your log file. If you want to test it out, I recommend\\n# saving a copy of one and editing it to have however many events you'd like\\nlogfile = os.path.join(\\n    Path.home(),\\n    r\\\"AppData\\\\LocalLow\\\\Wizards Of The Coast\\\\MTGA\\\\Player.log\\\",\\n    #     r\\\"AppData\\\\LocalLow\\\\Wizards Of The Coast\\\\MTGA\\\\Player_vow_premier_draft_midpoint.log\\\",\\n)\\n\\nprint(f\\\"looking for logfile at: {logfile}\\\")\\n\\n\\n# This may pop up a dialog the first time, I'm not sure.\\ntoken = get_config()\\n\\n# This controls what displays. you can print(df) to see your column options\\nuseful_cols = [\\n    \\\"name\\\",\\n    \\\"color\\\",\\n    \\\"types\\\",\\n    \\\"rarity\\\",\\n    \\\"alsa\\\",\\n    \\\"ata\\\",\\n    \\\"oh wr\\\",\\n    \\\"gd wr\\\",\\n    \\\"iwd\\\",\\n]\\n\\n# this controls formatting of columns\\npercentage_cols = [\\\"iwd\\\", \\\"oh wr\\\", \\\"gd wr\\\"]\\nnumeric_cols = [\\\"alsa\\\", \\\"ata\\\"]\\n\\n# allows you to override the CSS of the dash app\\nexternal_stylesheets = [\\\"https://codepen.io/chriddyp/pen/bWLwgP.css\\\", dbc.themes.GRID]\\n\\n# modify this to change the cell styling in the tables\\ncell_styling = {\\\"textAlign\\\": \\\"left\\\", \\\"padding\\\": \\\"5px\\\"}\\n\\n# making server explicit so that eventually a Follower object could\\n# run separately and just post relevant events to an event API\\n# flask_app = Flask(__name__)\\n\\n# the core of the app\\napp = dash.Dash(\\n    __name__,\\n    #     server=flask_app,\\n    #     url_base_pathname=\\\"/dash/\\\",\\n    external_stylesheets=external_stylesheets,\\n)\\napp.layout = html.Div(\\n    html.Div(\\n        [\\n            dbc.Container(\\n                [\\n                    dbc.Row(html.H4(\\\"Current Options\\\")),\\n                    dbc.Row(html.Div(id=\\\"live-update-text\\\")),\\n                    dbc.Row(html.Div(id=\\\"current-pick-table-holder\\\")),\\n                    dbc.Row(html.H4(\\\"Draft Info\\\")),\\n                    dbc.Row(html.Div(id=\\\"draft-tracking-info\\\")),\\n                    dbc.Row(html.H4(\\\"Pool So Far\\\")),\\n                    dbc.Row(html.Div(id=\\\"pool-table-holder\\\")),\\n                ]\\n            ),\\n            dcc.Interval(\\n                id=\\\"interval-component\\\",\\n                interval=N_SECONDS * 1000,  # in milliseconds\\n                n_intervals=0,\\n            ),\\n        ]\\n    )\\n)\\n# init draft-level trackers that live outside the Follower\\nlocal_alsa_tracker: ALSATrackerType = {}\\nlocal_color_tracker: ColorTrackerType = {}\\nhistory = {}\\n\\n\\ndef get_color_count_graph(inp_df: pd.DataFrame) -> plotly.graph_objects.Figure:\\n    \\\"\\\"\\\"\\n    Count the occurences of each \\\"color\\\" symbol in the card data's \\\"color\\\" column\\n    in the pool of cards you've drafted so far.\\n    \\\"\\\"\\\"\\n    color_counts = (\\n        inp_df.color.apply(lambda x: list(x) if isinstance(x, str) else [])\\n        .explode()\\n        .value_counts()\\n        .reset_index()\\n        .rename(columns={\\\"index\\\": \\\"Color\\\", \\\"color\\\": \\\"Count\\\"})\\n    )\\n    color_hexes = [\\\"#838383\\\", \\\"#26b569\\\", \\\"#f85656\\\", \\\"#aae0fa\\\", \\\"#fef2be\\\"]\\n    missing_colors = [\\n        c for c in (\\\"B\\\", \\\"G\\\", \\\"R\\\", \\\"U\\\", \\\"W\\\") if c not in color_counts.Color.values\\n    ]\\n    missing_df = pd.DataFrame(\\n        [[c, 0] for c in missing_colors], columns=[\\\"Color\\\", \\\"Count\\\"]\\n    )\\n    color_counts.append(missing_df)\\n    color_counts = color_counts.sort_values(\\\"Color\\\")\\n\\n    fig = go.Figure(\\n        data=[\\n            go.Bar(name=x[0], x=[x[0]], y=[x[1]], marker_color=color_hexes[i])\\n            for i, x in enumerate(color_counts.values)\\n        ],\\n    )\\n    fig.update_layout(\\n        title={\\n            \\\"text\\\": \\\"Card Color Counts\\\",\\n            \\\"y\\\": 0.9,\\n            \\\"x\\\": 0.5,\\n            \\\"xanchor\\\": \\\"center\\\",\\n            \\\"yanchor\\\": \\\"top\\\",\\n        }\\n    )\\n    return fig\\n\\n\\ndef get_type_summary(inp_df: pd.DataFrame) -> Tuple[pd.DataFrame, pd.DataFrame]:\\n    \\\"\\\"\\\"\\n    Get counts of the core card types and of the other keywords in your\\n    pool of drafted cards so far.\\n    \\\"\\\"\\\"\\n    copied = inp_df.copy()\\n    card_types = [\\n        \\\"Land\\\",\\n        \\\"Artifact\\\",\\n        \\\"Creature\\\",\\n        \\\"Enchantment\\\",\\n        \\\"Planeswalker\\\",\\n        \\\"Instant\\\",\\n        \\\"Sorcery\\\",\\n    ]\\n    copied[\\\"keywords\\\"] = copied[\\\"types\\\"].apply(\\n        lambda x: [t.strip() for t in x.split(\\\" \\\") if t.strip() not in (\\\"\\\", \\\"-\\\")]\\n    )\\n    vc = copied[\\\"keywords\\\"].explode().value_counts().reset_index()\\n    main = (\\n        vc[vc[\\\"index\\\"].apply(lambda x: x in card_types)]\\n        .copy()\\n        .rename(columns={\\\"index\\\": \\\"type\\\", \\\"keywords\\\": \\\"count\\\"})\\n    )\\n    other = (\\n        vc[~vc[\\\"index\\\"].apply(lambda x: x in card_types)]\\n        .copy()\\n        .rename(columns={\\\"index\\\": \\\"keyword\\\", \\\"keywords\\\": \\\"count\\\"})\\n    )\\n    return main, other\\n\\n\\ndef get_draft_level_info(\\n    alsa_tracker: ALSATrackerType, color_tracker: ColorTrackerType\\n):\\n    # handle the color tracking\\n    color_df = pd.DataFrame(\\n        [[k, v] for k, v in color_tracker.items()],\\n        columns=[\\\"color\\\", \\\"cards passed to you\\\"],\\n    ).sort_values(\\\"color\\\")\\n\\n    # handle the ALSA tracking\\n    alsa_diff_sums = {\\\"B\\\": 0, \\\"G\\\": 0, \\\"R\\\": 0, \\\"U\\\": 0, \\\"W\\\": 0}\\n    for key, alsa_diff_dict in alsa_tracker.items():\\n        for inner_color, val in alsa_diff_dict.items():\\n            alsa_diff_sums[inner_color] += np.sum(val)\\n    alsa_df = pd.DataFrame(\\n        [[k, v] for k, v in alsa_diff_sums.items()],\\n        columns=[\\\"color\\\", \\\"ALSA difference sum\\\"],\\n    )\\n    return color_df, alsa_df\\n\\n\\ndef get_pool_summary(inp_df: pd.DataFrame):\\n    \\\"\\\"\\\"\\n    Return all of the summary objects:\\n      - color count graph\\n      - type count df\\n      - keyword count df\\n    \\\"\\\"\\\"\\n    color_count_graph = get_color_count_graph(inp_df)\\n    main_type_sum, other_type_sum = get_type_summary(inp_df)\\n    return color_count_graph, main_type_sum, other_type_sum\\n\\n\\ndef add_format_to_cols(col_dicts: List[Dict[str, Any]]):\\n    for col_dict in col_dicts:\\n        if col_dict[\\\"name\\\"] in percentage_cols:\\n            col_dict[\\\"format\\\"] = Format(precision=1, scheme=Scheme.percentage)\\n            col_dict[\\\"type\\\"] = \\\"numeric\\\"\\n        if col_dict[\\\"name\\\"] in numeric_cols:\\n            col_dict[\\\"format\\\"] = Format(precision=1, scheme=Scheme.fixed)\\n            col_dict[\\\"type\\\"] = \\\"numeric\\\"\\n    return col_dicts\\n\\n\\ndef get_preds(model: DraftTransformer, follower, card_ids):\\n    model.eval()\\n    hist = follower.history\\n    num_hist_rounds = len(follower.pool_card_ids)\\n    hist = [\\n        [card_ids.get(i, 0) for i in v]\\n        for n, (k, v) in enumerate(\\n            sorted(\\n                hist.items(),\\n                key=lambda x: int(x[0].split(\\\"_\\\")[0]) * 20 + int(x[0].split(\\\"_\\\")[1]),\\n            )\\n        )\\n        if n < num_hist_rounds\\n    ]\\n    valid_pick_options = [\\n        i for i in getattr(follower, \\\"pick_options\\\", []) if i in df.index\\n    ]\\n    valid_opt_names = follower.df.loc[valid_pick_options].name.values\\n    pick_options = [\\n        card_ids.get(i, 0) for i in follower.df.loc[valid_pick_options].name.values\\n    ]\\n    print(pick_options)\\n    valid_pool = [i for i in follower.pool_card_ids if i in df.index]\\n    pool = [card_ids.get(i, 0) for i in follower.df.loc[valid_pool].name.values]\\n\\n    batch = collate_batch(\\n        [{\\\"history\\\": hist, \\\"options\\\": pick_options, \\\"pool\\\": pool}],\\n        device=\\\"cpu\\\",\\n        inference=True,\\n    )\\n    card_logits, game_win_pred = model(batch)\\n    card_probs = np.round(np.exp(card_logits.detach().numpy()[0]), 3)\\n    pred_df = pd.DataFrame(zip(valid_opt_names, card_probs), columns=[\\\"name\\\", \\\"pred\\\"])\\n    return pred_df, game_win_pred.detach().numpy()\\n\\n\\n# every N seconds, our Interval fires, and we update most of the app\\n# by parsing the log\\n@app.callback(\\n    Output(\\\"live-update-text\\\", \\\"children\\\"),\\n    Output(\\\"current-pick-table-holder\\\", \\\"children\\\"),\\n    Output(\\\"draft-tracking-info\\\", \\\"children\\\"),\\n    Output(\\\"pool-table-holder\\\", \\\"children\\\"),\\n    Input(\\\"interval-component\\\", \\\"n_intervals\\\"),\\n)\\ndef update_metrics(n):\\n    \\\"\\\"\\\"\\n    Update the whole app by parsing the log file\\n    \\\"\\\"\\\"\\n    t0 = time.time()\\n    # create a 17Lands client with the API interaction removed\\n    # TODO: just fix __init__ to set these\\n    follower = DashFollower(token, \\\"\\\")\\n    follower.alsa_tracker = local_alsa_tracker\\n    follower.color_tracker = local_color_tracker\\n    follower.history = history\\n    follower.df = df\\n    follower.late_alsa_diff_threshold = LATE_ALSA_DIFF_THRESHOLD\\n    follower.multicolor_alsa_diff_factor = MULTICOLOR_ALSA_DIFF_FACTOR\\n    # parse your whole log\\n    r = follower.parse_log(logfile, follow=False, skip_bytes=SEEK_TO)\\n    t1 = time.time()\\n    print(f\\\"parsed file in {t1 - t0} seconds\\\")\\n\\n    color_df, alsa_df = get_draft_level_info(local_alsa_tracker, local_color_tracker)\\n    pred_df, num_wins = get_preds(model, follower, card_ids)\\n\\n    style = {\\\"padding\\\": \\\"5px\\\", \\\"fontSize\\\": \\\"16px\\\"}\\n    # get the cards available to be picked\\n    valid_pick_options = [\\n        i for i in getattr(follower, \\\"pick_options\\\", []) if i in df.index\\n    ]\\n    picked_df = df.loc[valid_pick_options, useful_cols].sort_values(\\n        \\\"iwd\\\", ascending=False\\n    )\\n    picked_df = pd.merge(\\n        picked_df, pred_df, left_on=\\\"name\\\", right_on=\\\"name\\\", how=\\\"left\\\"\\n    )\\n    # get the cards you've already drafted\\n    pool_df = df.loc[getattr(follower, \\\"pool_card_ids\\\", []), useful_cols].sort_values(\\n        \\\"iwd\\\", ascending=False\\n    )\\n    # turn them both into Table objects\\n    picked_cols = [{\\\"name\\\": i, \\\"id\\\": i} for i in picked_df.columns]\\n    add_format_to_cols(picked_cols)\\n    pick_table = html.Div(\\n        dash_table.DataTable(\\n            id=\\\"pick_table\\\",\\n            columns=picked_cols,\\n            data=picked_df.to_dict(\\\"records\\\"),\\n            style_cell=cell_styling,\\n        ),\\n        style={\\\"width\\\": \\\"80%\\\", \\\"margin\\\": \\\"auto\\\"},\\n    )\\n    pool_table = html.Div(\\n        dash_table.DataTable(\\n            id=\\\"pool_table\\\",\\n            columns=add_format_to_cols([{\\\"name\\\": i, \\\"id\\\": i} for i in pool_df.columns]),\\n            data=pool_df.to_dict(\\\"records\\\"),\\n            style_cell=cell_styling,\\n        )\\n    )\\n    # get the summary statistics for your pool\\n    pool_summary, main_type_sum, other_type_sum = get_pool_summary(pool_df)\\n    main_type_sum = dash_table.DataTable(\\n        id=\\\"main_type_table\\\",\\n        columns=[{\\\"name\\\": i, \\\"id\\\": i} for i in main_type_sum.columns],\\n        data=main_type_sum.to_dict(\\\"records\\\"),\\n        style_cell=cell_styling,\\n    )\\n    other_type_sum = dash_table.DataTable(\\n        id=\\\"other_type_table\\\",\\n        columns=[{\\\"name\\\": i, \\\"id\\\": i} for i in other_type_sum.columns],\\n        data=other_type_sum.to_dict(\\\"records\\\"),\\n        style_cell=cell_styling,\\n    )\\n    # update the container with the summary info\\n    curr_div = dbc.Container(\\n        dbc.Row(\\n            [\\n                dbc.Col(pool_table, width={\\\"size\\\": 8}),\\n                dbc.Col(\\n                    [\\n                        dbc.Row(dcc.Graph(figure=pool_summary)),\\n                        dbc.Row(main_type_sum),\\n                        dbc.Row(html.Div(\\\"--\\\")),\\n                        dbc.Row(other_type_sum),\\n                    ],\\n                    width={\\\"size\\\": 4},\\n                ),\\n            ]\\n        )\\n    )\\n    draft_info_div = dbc.Container(\\n        dbc.Row(\\n            [\\n                dbc.Col(\\n                    dash_table.DataTable(\\n                        columns=[{\\\"name\\\": i, \\\"id\\\": i} for i in color_df.columns],\\n                        data=color_df.to_dict(\\\"records\\\"),\\n                        style_cell=cell_styling,\\n                    ),\\n                    width={\\\"size\\\": 4},\\n                ),\\n                dbc.Col(\\n                    dash_table.DataTable(\\n                        columns=[{\\\"name\\\": i, \\\"id\\\": i} for i in alsa_df.columns],\\n                        data=alsa_df.to_dict(\\\"records\\\"),\\n                        style_cell=cell_styling,\\n                    ),\\n                    width={\\\"size\\\": 4},\\n                ),\\n            ]\\n        )\\n    )\\n    print(f\\\"rebuilt dash components in {time.time() - t1} seconds\\\")\\n    return [\\n        html.Span(\\n            f\\\"Pack {follower.pack_number}, Pick {follower.pick_number}\\\", style=style\\n        ),\\n        pick_table,\\n        draft_info_div,\\n        curr_div,\\n    ]\\n\\n\\nif __name__ == \\\"__main__\\\":\\n    app.run_server()\";\n",
       "                var nbb_formatted_code = \"# number of seconds between refreshes. Needs to be long enough to fully parse your\\n# .log file. If your file is huge, this could be an issue, and you may want to exit\\n# and reload the game\\nN_SECONDS = 10\\n\\n# threshold for (pick_num - ALSA) at which we consider a\\n# card to be signifying some amount of \\\"openness\\\" of that\\n# color in the draft\\nLATE_ALSA_DIFF_THRESHOLD = 0.5\\n\\n# if we see cards that show up \\\"late\\\" that are multicolor,\\n# how much should we weight this as an indicator that\\n# each of their colors is open?\\nMULTICOLOR_ALSA_DIFF_FACTOR = 0.5\\n\\n# this parameter should be 0, but can be set to larger values to\\n# accommodate large logs. If you've played a lot and have many\\n# MB of data in your log, you might be better off skipping\\n# a lot of it. This will skip the first SEEK_TO bytes of your\\n# log. SET AT YOUR OWN RISK\\n\\n# SEEK_TO = 32e6  skips 32MB\\n# SEEK_TO = 5e6  # skips 5MB\\nSEEK_TO = 0\\n\\n# This is the path to your log file. If you want to test it out, I recommend\\n# saving a copy of one and editing it to have however many events you'd like\\nlogfile = os.path.join(\\n    Path.home(),\\n    r\\\"AppData\\\\LocalLow\\\\Wizards Of The Coast\\\\MTGA\\\\Player.log\\\",\\n    #     r\\\"AppData\\\\LocalLow\\\\Wizards Of The Coast\\\\MTGA\\\\Player_vow_premier_draft_midpoint.log\\\",\\n)\\n\\nprint(f\\\"looking for logfile at: {logfile}\\\")\\n\\n\\n# This may pop up a dialog the first time, I'm not sure.\\ntoken = get_config()\\n\\n# This controls what displays. you can print(df) to see your column options\\nuseful_cols = [\\n    \\\"name\\\",\\n    \\\"color\\\",\\n    \\\"types\\\",\\n    \\\"rarity\\\",\\n    \\\"alsa\\\",\\n    \\\"ata\\\",\\n    \\\"oh wr\\\",\\n    \\\"gd wr\\\",\\n    \\\"iwd\\\",\\n]\\n\\n# this controls formatting of columns\\npercentage_cols = [\\\"iwd\\\", \\\"oh wr\\\", \\\"gd wr\\\"]\\nnumeric_cols = [\\\"alsa\\\", \\\"ata\\\"]\\n\\n# allows you to override the CSS of the dash app\\nexternal_stylesheets = [\\\"https://codepen.io/chriddyp/pen/bWLwgP.css\\\", dbc.themes.GRID]\\n\\n# modify this to change the cell styling in the tables\\ncell_styling = {\\\"textAlign\\\": \\\"left\\\", \\\"padding\\\": \\\"5px\\\"}\\n\\n# making server explicit so that eventually a Follower object could\\n# run separately and just post relevant events to an event API\\n# flask_app = Flask(__name__)\\n\\n# the core of the app\\napp = dash.Dash(\\n    __name__,\\n    #     server=flask_app,\\n    #     url_base_pathname=\\\"/dash/\\\",\\n    external_stylesheets=external_stylesheets,\\n)\\napp.layout = html.Div(\\n    html.Div(\\n        [\\n            dbc.Container(\\n                [\\n                    dbc.Row(html.H4(\\\"Current Options\\\")),\\n                    dbc.Row(html.Div(id=\\\"live-update-text\\\")),\\n                    dbc.Row(html.Div(id=\\\"current-pick-table-holder\\\")),\\n                    dbc.Row(html.H4(\\\"Draft Info\\\")),\\n                    dbc.Row(html.Div(id=\\\"draft-tracking-info\\\")),\\n                    dbc.Row(html.H4(\\\"Pool So Far\\\")),\\n                    dbc.Row(html.Div(id=\\\"pool-table-holder\\\")),\\n                ]\\n            ),\\n            dcc.Interval(\\n                id=\\\"interval-component\\\",\\n                interval=N_SECONDS * 1000,  # in milliseconds\\n                n_intervals=0,\\n            ),\\n        ]\\n    )\\n)\\n# init draft-level trackers that live outside the Follower\\nlocal_alsa_tracker: ALSATrackerType = {}\\nlocal_color_tracker: ColorTrackerType = {}\\nhistory = {}\\n\\n\\ndef get_color_count_graph(inp_df: pd.DataFrame) -> plotly.graph_objects.Figure:\\n    \\\"\\\"\\\"\\n    Count the occurences of each \\\"color\\\" symbol in the card data's \\\"color\\\" column\\n    in the pool of cards you've drafted so far.\\n    \\\"\\\"\\\"\\n    color_counts = (\\n        inp_df.color.apply(lambda x: list(x) if isinstance(x, str) else [])\\n        .explode()\\n        .value_counts()\\n        .reset_index()\\n        .rename(columns={\\\"index\\\": \\\"Color\\\", \\\"color\\\": \\\"Count\\\"})\\n    )\\n    color_hexes = [\\\"#838383\\\", \\\"#26b569\\\", \\\"#f85656\\\", \\\"#aae0fa\\\", \\\"#fef2be\\\"]\\n    missing_colors = [\\n        c for c in (\\\"B\\\", \\\"G\\\", \\\"R\\\", \\\"U\\\", \\\"W\\\") if c not in color_counts.Color.values\\n    ]\\n    missing_df = pd.DataFrame(\\n        [[c, 0] for c in missing_colors], columns=[\\\"Color\\\", \\\"Count\\\"]\\n    )\\n    color_counts.append(missing_df)\\n    color_counts = color_counts.sort_values(\\\"Color\\\")\\n\\n    fig = go.Figure(\\n        data=[\\n            go.Bar(name=x[0], x=[x[0]], y=[x[1]], marker_color=color_hexes[i])\\n            for i, x in enumerate(color_counts.values)\\n        ],\\n    )\\n    fig.update_layout(\\n        title={\\n            \\\"text\\\": \\\"Card Color Counts\\\",\\n            \\\"y\\\": 0.9,\\n            \\\"x\\\": 0.5,\\n            \\\"xanchor\\\": \\\"center\\\",\\n            \\\"yanchor\\\": \\\"top\\\",\\n        }\\n    )\\n    return fig\\n\\n\\ndef get_type_summary(inp_df: pd.DataFrame) -> Tuple[pd.DataFrame, pd.DataFrame]:\\n    \\\"\\\"\\\"\\n    Get counts of the core card types and of the other keywords in your\\n    pool of drafted cards so far.\\n    \\\"\\\"\\\"\\n    copied = inp_df.copy()\\n    card_types = [\\n        \\\"Land\\\",\\n        \\\"Artifact\\\",\\n        \\\"Creature\\\",\\n        \\\"Enchantment\\\",\\n        \\\"Planeswalker\\\",\\n        \\\"Instant\\\",\\n        \\\"Sorcery\\\",\\n    ]\\n    copied[\\\"keywords\\\"] = copied[\\\"types\\\"].apply(\\n        lambda x: [t.strip() for t in x.split(\\\" \\\") if t.strip() not in (\\\"\\\", \\\"-\\\")]\\n    )\\n    vc = copied[\\\"keywords\\\"].explode().value_counts().reset_index()\\n    main = (\\n        vc[vc[\\\"index\\\"].apply(lambda x: x in card_types)]\\n        .copy()\\n        .rename(columns={\\\"index\\\": \\\"type\\\", \\\"keywords\\\": \\\"count\\\"})\\n    )\\n    other = (\\n        vc[~vc[\\\"index\\\"].apply(lambda x: x in card_types)]\\n        .copy()\\n        .rename(columns={\\\"index\\\": \\\"keyword\\\", \\\"keywords\\\": \\\"count\\\"})\\n    )\\n    return main, other\\n\\n\\ndef get_draft_level_info(\\n    alsa_tracker: ALSATrackerType, color_tracker: ColorTrackerType\\n):\\n    # handle the color tracking\\n    color_df = pd.DataFrame(\\n        [[k, v] for k, v in color_tracker.items()],\\n        columns=[\\\"color\\\", \\\"cards passed to you\\\"],\\n    ).sort_values(\\\"color\\\")\\n\\n    # handle the ALSA tracking\\n    alsa_diff_sums = {\\\"B\\\": 0, \\\"G\\\": 0, \\\"R\\\": 0, \\\"U\\\": 0, \\\"W\\\": 0}\\n    for key, alsa_diff_dict in alsa_tracker.items():\\n        for inner_color, val in alsa_diff_dict.items():\\n            alsa_diff_sums[inner_color] += np.sum(val)\\n    alsa_df = pd.DataFrame(\\n        [[k, v] for k, v in alsa_diff_sums.items()],\\n        columns=[\\\"color\\\", \\\"ALSA difference sum\\\"],\\n    )\\n    return color_df, alsa_df\\n\\n\\ndef get_pool_summary(inp_df: pd.DataFrame):\\n    \\\"\\\"\\\"\\n    Return all of the summary objects:\\n      - color count graph\\n      - type count df\\n      - keyword count df\\n    \\\"\\\"\\\"\\n    color_count_graph = get_color_count_graph(inp_df)\\n    main_type_sum, other_type_sum = get_type_summary(inp_df)\\n    return color_count_graph, main_type_sum, other_type_sum\\n\\n\\ndef add_format_to_cols(col_dicts: List[Dict[str, Any]]):\\n    for col_dict in col_dicts:\\n        if col_dict[\\\"name\\\"] in percentage_cols:\\n            col_dict[\\\"format\\\"] = Format(precision=1, scheme=Scheme.percentage)\\n            col_dict[\\\"type\\\"] = \\\"numeric\\\"\\n        if col_dict[\\\"name\\\"] in numeric_cols:\\n            col_dict[\\\"format\\\"] = Format(precision=1, scheme=Scheme.fixed)\\n            col_dict[\\\"type\\\"] = \\\"numeric\\\"\\n    return col_dicts\\n\\n\\ndef get_preds(model: DraftTransformer, follower, card_ids):\\n    model.eval()\\n    hist = follower.history\\n    num_hist_rounds = len(follower.pool_card_ids)\\n    hist = [\\n        [card_ids.get(i, 0) for i in v]\\n        for n, (k, v) in enumerate(\\n            sorted(\\n                hist.items(),\\n                key=lambda x: int(x[0].split(\\\"_\\\")[0]) * 20 + int(x[0].split(\\\"_\\\")[1]),\\n            )\\n        )\\n        if n < num_hist_rounds\\n    ]\\n    valid_pick_options = [\\n        i for i in getattr(follower, \\\"pick_options\\\", []) if i in df.index\\n    ]\\n    valid_opt_names = follower.df.loc[valid_pick_options].name.values\\n    pick_options = [\\n        card_ids.get(i, 0) for i in follower.df.loc[valid_pick_options].name.values\\n    ]\\n    print(pick_options)\\n    valid_pool = [i for i in follower.pool_card_ids if i in df.index]\\n    pool = [card_ids.get(i, 0) for i in follower.df.loc[valid_pool].name.values]\\n\\n    batch = collate_batch(\\n        [{\\\"history\\\": hist, \\\"options\\\": pick_options, \\\"pool\\\": pool}],\\n        device=\\\"cpu\\\",\\n        inference=True,\\n    )\\n    card_logits, game_win_pred = model(batch)\\n    card_probs = np.round(np.exp(card_logits.detach().numpy()[0]), 3)\\n    pred_df = pd.DataFrame(zip(valid_opt_names, card_probs), columns=[\\\"name\\\", \\\"pred\\\"])\\n    return pred_df, game_win_pred.detach().numpy()\\n\\n\\n# every N seconds, our Interval fires, and we update most of the app\\n# by parsing the log\\n@app.callback(\\n    Output(\\\"live-update-text\\\", \\\"children\\\"),\\n    Output(\\\"current-pick-table-holder\\\", \\\"children\\\"),\\n    Output(\\\"draft-tracking-info\\\", \\\"children\\\"),\\n    Output(\\\"pool-table-holder\\\", \\\"children\\\"),\\n    Input(\\\"interval-component\\\", \\\"n_intervals\\\"),\\n)\\ndef update_metrics(n):\\n    \\\"\\\"\\\"\\n    Update the whole app by parsing the log file\\n    \\\"\\\"\\\"\\n    t0 = time.time()\\n    # create a 17Lands client with the API interaction removed\\n    # TODO: just fix __init__ to set these\\n    follower = DashFollower(token, \\\"\\\")\\n    follower.alsa_tracker = local_alsa_tracker\\n    follower.color_tracker = local_color_tracker\\n    follower.history = history\\n    follower.df = df\\n    follower.late_alsa_diff_threshold = LATE_ALSA_DIFF_THRESHOLD\\n    follower.multicolor_alsa_diff_factor = MULTICOLOR_ALSA_DIFF_FACTOR\\n    # parse your whole log\\n    r = follower.parse_log(logfile, follow=False, skip_bytes=SEEK_TO)\\n    t1 = time.time()\\n    print(f\\\"parsed file in {t1 - t0} seconds\\\")\\n\\n    color_df, alsa_df = get_draft_level_info(local_alsa_tracker, local_color_tracker)\\n    pred_df, num_wins = get_preds(model, follower, card_ids)\\n\\n    style = {\\\"padding\\\": \\\"5px\\\", \\\"fontSize\\\": \\\"16px\\\"}\\n    # get the cards available to be picked\\n    valid_pick_options = [\\n        i for i in getattr(follower, \\\"pick_options\\\", []) if i in df.index\\n    ]\\n    picked_df = df.loc[valid_pick_options, useful_cols].sort_values(\\n        \\\"iwd\\\", ascending=False\\n    )\\n    picked_df = pd.merge(\\n        picked_df, pred_df, left_on=\\\"name\\\", right_on=\\\"name\\\", how=\\\"left\\\"\\n    )\\n    # get the cards you've already drafted\\n    pool_df = df.loc[getattr(follower, \\\"pool_card_ids\\\", []), useful_cols].sort_values(\\n        \\\"iwd\\\", ascending=False\\n    )\\n    # turn them both into Table objects\\n    picked_cols = [{\\\"name\\\": i, \\\"id\\\": i} for i in picked_df.columns]\\n    add_format_to_cols(picked_cols)\\n    pick_table = html.Div(\\n        dash_table.DataTable(\\n            id=\\\"pick_table\\\",\\n            columns=picked_cols,\\n            data=picked_df.to_dict(\\\"records\\\"),\\n            style_cell=cell_styling,\\n        ),\\n        style={\\\"width\\\": \\\"80%\\\", \\\"margin\\\": \\\"auto\\\"},\\n    )\\n    pool_table = html.Div(\\n        dash_table.DataTable(\\n            id=\\\"pool_table\\\",\\n            columns=add_format_to_cols([{\\\"name\\\": i, \\\"id\\\": i} for i in pool_df.columns]),\\n            data=pool_df.to_dict(\\\"records\\\"),\\n            style_cell=cell_styling,\\n        )\\n    )\\n    # get the summary statistics for your pool\\n    pool_summary, main_type_sum, other_type_sum = get_pool_summary(pool_df)\\n    main_type_sum = dash_table.DataTable(\\n        id=\\\"main_type_table\\\",\\n        columns=[{\\\"name\\\": i, \\\"id\\\": i} for i in main_type_sum.columns],\\n        data=main_type_sum.to_dict(\\\"records\\\"),\\n        style_cell=cell_styling,\\n    )\\n    other_type_sum = dash_table.DataTable(\\n        id=\\\"other_type_table\\\",\\n        columns=[{\\\"name\\\": i, \\\"id\\\": i} for i in other_type_sum.columns],\\n        data=other_type_sum.to_dict(\\\"records\\\"),\\n        style_cell=cell_styling,\\n    )\\n    # update the container with the summary info\\n    curr_div = dbc.Container(\\n        dbc.Row(\\n            [\\n                dbc.Col(pool_table, width={\\\"size\\\": 8}),\\n                dbc.Col(\\n                    [\\n                        dbc.Row(dcc.Graph(figure=pool_summary)),\\n                        dbc.Row(main_type_sum),\\n                        dbc.Row(html.Div(\\\"--\\\")),\\n                        dbc.Row(other_type_sum),\\n                    ],\\n                    width={\\\"size\\\": 4},\\n                ),\\n            ]\\n        )\\n    )\\n    draft_info_div = dbc.Container(\\n        dbc.Row(\\n            [\\n                dbc.Col(\\n                    dash_table.DataTable(\\n                        columns=[{\\\"name\\\": i, \\\"id\\\": i} for i in color_df.columns],\\n                        data=color_df.to_dict(\\\"records\\\"),\\n                        style_cell=cell_styling,\\n                    ),\\n                    width={\\\"size\\\": 4},\\n                ),\\n                dbc.Col(\\n                    dash_table.DataTable(\\n                        columns=[{\\\"name\\\": i, \\\"id\\\": i} for i in alsa_df.columns],\\n                        data=alsa_df.to_dict(\\\"records\\\"),\\n                        style_cell=cell_styling,\\n                    ),\\n                    width={\\\"size\\\": 4},\\n                ),\\n            ]\\n        )\\n    )\\n    print(f\\\"rebuilt dash components in {time.time() - t1} seconds\\\")\\n    return [\\n        html.Span(\\n            f\\\"Pack {follower.pack_number}, Pick {follower.pick_number}\\\", style=style\\n        ),\\n        pick_table,\\n        draft_info_div,\\n        curr_div,\\n    ]\\n\\n\\nif __name__ == \\\"__main__\\\":\\n    app.run_server()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# number of seconds between refreshes. Needs to be long enough to fully parse your\n",
    "# .log file. If your file is huge, this could be an issue, and you may want to exit\n",
    "# and reload the game\n",
    "N_SECONDS = 10\n",
    "\n",
    "# threshold for (pick_num - ALSA) at which we consider a\n",
    "# card to be signifying some amount of \"openness\" of that\n",
    "# color in the draft\n",
    "LATE_ALSA_DIFF_THRESHOLD = 0.5\n",
    "\n",
    "# if we see cards that show up \"late\" that are multicolor,\n",
    "# how much should we weight this as an indicator that\n",
    "# each of their colors is open?\n",
    "MULTICOLOR_ALSA_DIFF_FACTOR = 0.5\n",
    "\n",
    "# this parameter should be 0, but can be set to larger values to\n",
    "# accommodate large logs. If you've played a lot and have many\n",
    "# MB of data in your log, you might be better off skipping\n",
    "# a lot of it. This will skip the first SEEK_TO bytes of your\n",
    "# log. SET AT YOUR OWN RISK\n",
    "\n",
    "# SEEK_TO = 32e6  skips 32MB\n",
    "# SEEK_TO = 5e6  # skips 5MB\n",
    "SEEK_TO = 0\n",
    "\n",
    "# This is the path to your log file. If you want to test it out, I recommend\n",
    "# saving a copy of one and editing it to have however many events you'd like\n",
    "logfile = os.path.join(\n",
    "    Path.home(),\n",
    "    r\"AppData\\LocalLow\\Wizards Of The Coast\\MTGA\\Player.log\",\n",
    "    #     r\"AppData\\LocalLow\\Wizards Of The Coast\\MTGA\\Player_vow_premier_draft_midpoint.log\",\n",
    ")\n",
    "\n",
    "print(f\"looking for logfile at: {logfile}\")\n",
    "\n",
    "\n",
    "# This may pop up a dialog the first time, I'm not sure.\n",
    "token = get_config()\n",
    "\n",
    "# This controls what displays. you can print(df) to see your column options\n",
    "useful_cols = [\n",
    "    \"name\",\n",
    "    \"color\",\n",
    "    \"types\",\n",
    "    \"rarity\",\n",
    "    \"alsa\",\n",
    "    \"ata\",\n",
    "    \"oh wr\",\n",
    "    \"gd wr\",\n",
    "    \"iwd\",\n",
    "]\n",
    "\n",
    "# this controls formatting of columns\n",
    "percentage_cols = [\"iwd\", \"oh wr\", \"gd wr\"]\n",
    "numeric_cols = [\"alsa\", \"ata\"]\n",
    "\n",
    "# allows you to override the CSS of the dash app\n",
    "external_stylesheets = [\"https://codepen.io/chriddyp/pen/bWLwgP.css\", dbc.themes.GRID]\n",
    "\n",
    "# modify this to change the cell styling in the tables\n",
    "cell_styling = {\"textAlign\": \"left\", \"padding\": \"5px\"}\n",
    "\n",
    "# making server explicit so that eventually a Follower object could\n",
    "# run separately and just post relevant events to an event API\n",
    "# flask_app = Flask(__name__)\n",
    "\n",
    "# the core of the app\n",
    "app = dash.Dash(\n",
    "    __name__,\n",
    "    #     server=flask_app,\n",
    "    #     url_base_pathname=\"/dash/\",\n",
    "    external_stylesheets=external_stylesheets,\n",
    ")\n",
    "app.layout = html.Div(\n",
    "    html.Div(\n",
    "        [\n",
    "            dbc.Container(\n",
    "                [\n",
    "                    dbc.Row(html.H4(\"Current Options\")),\n",
    "                    dbc.Row(html.Div(id=\"live-update-text\")),\n",
    "                    dbc.Row(html.Div(id=\"current-pick-table-holder\")),\n",
    "                    dbc.Row(html.H4(\"Draft Info\")),\n",
    "                    dbc.Row(html.Div(id=\"draft-tracking-info\")),\n",
    "                    dbc.Row(html.H4(\"Pool So Far\")),\n",
    "                    dbc.Row(html.Div(id=\"pool-table-holder\")),\n",
    "                ]\n",
    "            ),\n",
    "            dcc.Interval(\n",
    "                id=\"interval-component\",\n",
    "                interval=N_SECONDS * 1000,  # in milliseconds\n",
    "                n_intervals=0,\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "# init draft-level trackers that live outside the Follower\n",
    "local_alsa_tracker: ALSATrackerType = {}\n",
    "local_color_tracker: ColorTrackerType = {}\n",
    "history = {}\n",
    "\n",
    "\n",
    "def get_color_count_graph(inp_df: pd.DataFrame) -> plotly.graph_objects.Figure:\n",
    "    \"\"\"\n",
    "    Count the occurences of each \"color\" symbol in the card data's \"color\" column\n",
    "    in the pool of cards you've drafted so far.\n",
    "    \"\"\"\n",
    "    color_counts = (\n",
    "        inp_df.color.apply(lambda x: list(x) if isinstance(x, str) else [])\n",
    "        .explode()\n",
    "        .value_counts()\n",
    "        .reset_index()\n",
    "        .rename(columns={\"index\": \"Color\", \"color\": \"Count\"})\n",
    "    )\n",
    "    color_hexes = [\"#838383\", \"#26b569\", \"#f85656\", \"#aae0fa\", \"#fef2be\"]\n",
    "    missing_colors = [\n",
    "        c for c in (\"B\", \"G\", \"R\", \"U\", \"W\") if c not in color_counts.Color.values\n",
    "    ]\n",
    "    missing_df = pd.DataFrame(\n",
    "        [[c, 0] for c in missing_colors], columns=[\"Color\", \"Count\"]\n",
    "    )\n",
    "    color_counts.append(missing_df)\n",
    "    color_counts = color_counts.sort_values(\"Color\")\n",
    "\n",
    "    fig = go.Figure(\n",
    "        data=[\n",
    "            go.Bar(name=x[0], x=[x[0]], y=[x[1]], marker_color=color_hexes[i])\n",
    "            for i, x in enumerate(color_counts.values)\n",
    "        ],\n",
    "    )\n",
    "    fig.update_layout(\n",
    "        title={\n",
    "            \"text\": \"Card Color Counts\",\n",
    "            \"y\": 0.9,\n",
    "            \"x\": 0.5,\n",
    "            \"xanchor\": \"center\",\n",
    "            \"yanchor\": \"top\",\n",
    "        }\n",
    "    )\n",
    "    return fig\n",
    "\n",
    "\n",
    "def get_type_summary(inp_df: pd.DataFrame) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Get counts of the core card types and of the other keywords in your\n",
    "    pool of drafted cards so far.\n",
    "    \"\"\"\n",
    "    copied = inp_df.copy()\n",
    "    card_types = [\n",
    "        \"Land\",\n",
    "        \"Artifact\",\n",
    "        \"Creature\",\n",
    "        \"Enchantment\",\n",
    "        \"Planeswalker\",\n",
    "        \"Instant\",\n",
    "        \"Sorcery\",\n",
    "    ]\n",
    "    copied[\"keywords\"] = copied[\"types\"].apply(\n",
    "        lambda x: [t.strip() for t in x.split(\" \") if t.strip() not in (\"\", \"-\")]\n",
    "    )\n",
    "    vc = copied[\"keywords\"].explode().value_counts().reset_index()\n",
    "    main = (\n",
    "        vc[vc[\"index\"].apply(lambda x: x in card_types)]\n",
    "        .copy()\n",
    "        .rename(columns={\"index\": \"type\", \"keywords\": \"count\"})\n",
    "    )\n",
    "    other = (\n",
    "        vc[~vc[\"index\"].apply(lambda x: x in card_types)]\n",
    "        .copy()\n",
    "        .rename(columns={\"index\": \"keyword\", \"keywords\": \"count\"})\n",
    "    )\n",
    "    return main, other\n",
    "\n",
    "\n",
    "def get_draft_level_info(\n",
    "    alsa_tracker: ALSATrackerType, color_tracker: ColorTrackerType\n",
    "):\n",
    "    # handle the color tracking\n",
    "    color_df = pd.DataFrame(\n",
    "        [[k, v] for k, v in color_tracker.items()],\n",
    "        columns=[\"color\", \"cards passed to you\"],\n",
    "    ).sort_values(\"color\")\n",
    "\n",
    "    # handle the ALSA tracking\n",
    "    alsa_diff_sums = {\"B\": 0, \"G\": 0, \"R\": 0, \"U\": 0, \"W\": 0}\n",
    "    for key, alsa_diff_dict in alsa_tracker.items():\n",
    "        for inner_color, val in alsa_diff_dict.items():\n",
    "            alsa_diff_sums[inner_color] += np.sum(val)\n",
    "    alsa_df = pd.DataFrame(\n",
    "        [[k, v] for k, v in alsa_diff_sums.items()],\n",
    "        columns=[\"color\", \"ALSA difference sum\"],\n",
    "    )\n",
    "    return color_df, alsa_df\n",
    "\n",
    "\n",
    "def get_pool_summary(inp_df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Return all of the summary objects:\n",
    "      - color count graph\n",
    "      - type count df\n",
    "      - keyword count df\n",
    "    \"\"\"\n",
    "    color_count_graph = get_color_count_graph(inp_df)\n",
    "    main_type_sum, other_type_sum = get_type_summary(inp_df)\n",
    "    return color_count_graph, main_type_sum, other_type_sum\n",
    "\n",
    "\n",
    "def add_format_to_cols(col_dicts: List[Dict[str, Any]]):\n",
    "    for col_dict in col_dicts:\n",
    "        if col_dict[\"name\"] in percentage_cols:\n",
    "            col_dict[\"format\"] = Format(precision=1, scheme=Scheme.percentage)\n",
    "            col_dict[\"type\"] = \"numeric\"\n",
    "        if col_dict[\"name\"] in numeric_cols:\n",
    "            col_dict[\"format\"] = Format(precision=1, scheme=Scheme.fixed)\n",
    "            col_dict[\"type\"] = \"numeric\"\n",
    "    return col_dicts\n",
    "\n",
    "\n",
    "def get_preds(model: DraftTransformer, follower, card_ids):\n",
    "    model.eval()\n",
    "    hist = follower.history\n",
    "    num_hist_rounds = len(follower.pool_card_ids)\n",
    "    hist = [\n",
    "        [card_ids.get(i, 0) for i in v]\n",
    "        for n, (k, v) in enumerate(\n",
    "            sorted(\n",
    "                hist.items(),\n",
    "                key=lambda x: int(x[0].split(\"_\")[0]) * 20 + int(x[0].split(\"_\")[1]),\n",
    "            )\n",
    "        )\n",
    "        if n < num_hist_rounds\n",
    "    ]\n",
    "    valid_pick_options = [\n",
    "        i for i in getattr(follower, \"pick_options\", []) if i in df.index\n",
    "    ]\n",
    "    valid_opt_names = follower.df.loc[valid_pick_options].name.values\n",
    "    pick_options = [\n",
    "        card_ids.get(i, 0) for i in follower.df.loc[valid_pick_options].name.values\n",
    "    ]\n",
    "    print(pick_options)\n",
    "    valid_pool = [i for i in follower.pool_card_ids if i in df.index]\n",
    "    pool = [card_ids.get(i, 0) for i in follower.df.loc[valid_pool].name.values]\n",
    "\n",
    "    batch = collate_batch(\n",
    "        [{\"history\": hist, \"options\": pick_options, \"pool\": pool}],\n",
    "        device=\"cpu\",\n",
    "        inference=True,\n",
    "    )\n",
    "    card_logits, game_win_pred = model(batch)\n",
    "    card_probs = np.round(np.exp(card_logits.detach().numpy()[0]), 3)\n",
    "    pred_df = pd.DataFrame(zip(valid_opt_names, card_probs), columns=[\"name\", \"pred\"])\n",
    "    return pred_df, game_win_pred.detach().numpy()\n",
    "\n",
    "\n",
    "# every N seconds, our Interval fires, and we update most of the app\n",
    "# by parsing the log\n",
    "@app.callback(\n",
    "    Output(\"live-update-text\", \"children\"),\n",
    "    Output(\"current-pick-table-holder\", \"children\"),\n",
    "    Output(\"draft-tracking-info\", \"children\"),\n",
    "    Output(\"pool-table-holder\", \"children\"),\n",
    "    Input(\"interval-component\", \"n_intervals\"),\n",
    ")\n",
    "def update_metrics(n):\n",
    "    \"\"\"\n",
    "    Update the whole app by parsing the log file\n",
    "    \"\"\"\n",
    "    t0 = time.time()\n",
    "    # create a 17Lands client with the API interaction removed\n",
    "    # TODO: just fix __init__ to set these\n",
    "    follower = DashFollower(token, \"\")\n",
    "    follower.alsa_tracker = local_alsa_tracker\n",
    "    follower.color_tracker = local_color_tracker\n",
    "    follower.history = history\n",
    "    follower.df = df\n",
    "    follower.late_alsa_diff_threshold = LATE_ALSA_DIFF_THRESHOLD\n",
    "    follower.multicolor_alsa_diff_factor = MULTICOLOR_ALSA_DIFF_FACTOR\n",
    "    # parse your whole log\n",
    "    r = follower.parse_log(logfile, follow=False, skip_bytes=SEEK_TO)\n",
    "    t1 = time.time()\n",
    "    print(f\"parsed file in {t1 - t0} seconds\")\n",
    "\n",
    "    color_df, alsa_df = get_draft_level_info(local_alsa_tracker, local_color_tracker)\n",
    "    pred_df, num_wins = get_preds(model, follower, card_ids)\n",
    "\n",
    "    style = {\"padding\": \"5px\", \"fontSize\": \"16px\"}\n",
    "    # get the cards available to be picked\n",
    "    valid_pick_options = [\n",
    "        i for i in getattr(follower, \"pick_options\", []) if i in df.index\n",
    "    ]\n",
    "    picked_df = df.loc[valid_pick_options, useful_cols].sort_values(\n",
    "        \"iwd\", ascending=False\n",
    "    )\n",
    "    picked_df = pd.merge(\n",
    "        picked_df, pred_df, left_on=\"name\", right_on=\"name\", how=\"left\"\n",
    "    )\n",
    "    # get the cards you've already drafted\n",
    "    pool_df = df.loc[getattr(follower, \"pool_card_ids\", []), useful_cols].sort_values(\n",
    "        \"iwd\", ascending=False\n",
    "    )\n",
    "    # turn them both into Table objects\n",
    "    picked_cols = [{\"name\": i, \"id\": i} for i in picked_df.columns]\n",
    "    add_format_to_cols(picked_cols)\n",
    "    pick_table = html.Div(\n",
    "        dash_table.DataTable(\n",
    "            id=\"pick_table\",\n",
    "            columns=picked_cols,\n",
    "            data=picked_df.to_dict(\"records\"),\n",
    "            style_cell=cell_styling,\n",
    "        ),\n",
    "        style={\"width\": \"80%\", \"margin\": \"auto\"},\n",
    "    )\n",
    "    pool_table = html.Div(\n",
    "        dash_table.DataTable(\n",
    "            id=\"pool_table\",\n",
    "            columns=add_format_to_cols([{\"name\": i, \"id\": i} for i in pool_df.columns]),\n",
    "            data=pool_df.to_dict(\"records\"),\n",
    "            style_cell=cell_styling,\n",
    "        )\n",
    "    )\n",
    "    # get the summary statistics for your pool\n",
    "    pool_summary, main_type_sum, other_type_sum = get_pool_summary(pool_df)\n",
    "    main_type_sum = dash_table.DataTable(\n",
    "        id=\"main_type_table\",\n",
    "        columns=[{\"name\": i, \"id\": i} for i in main_type_sum.columns],\n",
    "        data=main_type_sum.to_dict(\"records\"),\n",
    "        style_cell=cell_styling,\n",
    "    )\n",
    "    other_type_sum = dash_table.DataTable(\n",
    "        id=\"other_type_table\",\n",
    "        columns=[{\"name\": i, \"id\": i} for i in other_type_sum.columns],\n",
    "        data=other_type_sum.to_dict(\"records\"),\n",
    "        style_cell=cell_styling,\n",
    "    )\n",
    "    # update the container with the summary info\n",
    "    curr_div = dbc.Container(\n",
    "        dbc.Row(\n",
    "            [\n",
    "                dbc.Col(pool_table, width={\"size\": 8}),\n",
    "                dbc.Col(\n",
    "                    [\n",
    "                        dbc.Row(dcc.Graph(figure=pool_summary)),\n",
    "                        dbc.Row(main_type_sum),\n",
    "                        dbc.Row(html.Div(\"--\")),\n",
    "                        dbc.Row(other_type_sum),\n",
    "                    ],\n",
    "                    width={\"size\": 4},\n",
    "                ),\n",
    "            ]\n",
    "        )\n",
    "    )\n",
    "    draft_info_div = dbc.Container(\n",
    "        dbc.Row(\n",
    "            [\n",
    "                dbc.Col(\n",
    "                    dash_table.DataTable(\n",
    "                        columns=[{\"name\": i, \"id\": i} for i in color_df.columns],\n",
    "                        data=color_df.to_dict(\"records\"),\n",
    "                        style_cell=cell_styling,\n",
    "                    ),\n",
    "                    width={\"size\": 4},\n",
    "                ),\n",
    "                dbc.Col(\n",
    "                    dash_table.DataTable(\n",
    "                        columns=[{\"name\": i, \"id\": i} for i in alsa_df.columns],\n",
    "                        data=alsa_df.to_dict(\"records\"),\n",
    "                        style_cell=cell_styling,\n",
    "                    ),\n",
    "                    width={\"size\": 4},\n",
    "                ),\n",
    "            ]\n",
    "        )\n",
    "    )\n",
    "    print(f\"rebuilt dash components in {time.time() - t1} seconds\")\n",
    "    return [\n",
    "        html.Span(\n",
    "            f\"Pack {follower.pack_number}, Pick {follower.pick_number}\", style=style\n",
    "        ),\n",
    "        pick_table,\n",
    "        draft_info_div,\n",
    "        curr_div,\n",
    "    ]\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run_server()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a3a7c3c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 8;\n",
       "                var nbb_unformatted_code = \"follower = DashFollower(token, \\\"\\\")\\nfollower.alsa_tracker = local_alsa_tracker\\nfollower.color_tracker = local_color_tracker\\nfollower.df = df\\nfollower.late_alsa_diff_threshold = LATE_ALSA_DIFF_THRESHOLD\\nfollower.multicolor_alsa_diff_factor = MULTICOLOR_ALSA_DIFF_FACTOR\\nfollower.history = history\\n# parse your whole log\\nr = follower.parse_log(logfile, follow=False, skip_bytes=SEEK_TO)\";\n",
       "                var nbb_formatted_code = \"follower = DashFollower(token, \\\"\\\")\\nfollower.alsa_tracker = local_alsa_tracker\\nfollower.color_tracker = local_color_tracker\\nfollower.df = df\\nfollower.late_alsa_diff_threshold = LATE_ALSA_DIFF_THRESHOLD\\nfollower.multicolor_alsa_diff_factor = MULTICOLOR_ALSA_DIFF_FACTOR\\nfollower.history = history\\n# parse your whole log\\nr = follower.parse_log(logfile, follow=False, skip_bytes=SEEK_TO)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "follower = DashFollower(token, \"\")\n",
    "follower.alsa_tracker = local_alsa_tracker\n",
    "follower.color_tracker = local_color_tracker\n",
    "follower.df = df\n",
    "follower.late_alsa_diff_threshold = LATE_ALSA_DIFF_THRESHOLD\n",
    "follower.multicolor_alsa_diff_factor = MULTICOLOR_ALSA_DIFF_FACTOR\n",
    "follower.history = history\n",
    "# parse your whole log\n",
    "r = follower.parse_log(logfile, follow=False, skip_bytes=SEEK_TO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92781bd3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "962c911a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id\n",
       "79674.0       Satoru Umezawa\n",
       "79496.0    Network Disruptor\n",
       "Name: name, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 9;\n",
       "                var nbb_unformatted_code = \"df.loc[follower.pool_card_ids].name\";\n",
       "                var nbb_formatted_code = \"df.loc[follower.pool_card_ids].name\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.loc[follower.pool_card_ids].name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ffe7d78b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[82, 209, 134, 80, 239, 162, 106, 271, 25, 155, 297, 170]\n",
      "{'history': tensor([[[110, 145, 243, 163, 219, 181,  64, 127, 255,  83, 281, 169, 189,  50,\n",
      "            0],\n",
      "         [128, 284, 273,  11,  42, 231, 145, 117, 258, 218, 177, 169,  81,   0,\n",
      "            0],\n",
      "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "            0],\n",
      "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "            0],\n",
      "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "            0],\n",
      "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "            0],\n",
      "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "            0],\n",
      "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "            0],\n",
      "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "            0],\n",
      "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "            0],\n",
      "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "            0],\n",
      "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "            0],\n",
      "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "            0],\n",
      "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "            0],\n",
      "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "            0],\n",
      "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "            0],\n",
      "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "            0],\n",
      "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "            0],\n",
      "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "            0],\n",
      "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "            0],\n",
      "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "            0],\n",
      "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "            0],\n",
      "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "            0],\n",
      "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "            0],\n",
      "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "            0],\n",
      "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "            0],\n",
      "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "            0],\n",
      "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "            0],\n",
      "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "            0],\n",
      "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "            0],\n",
      "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "            0],\n",
      "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "            0],\n",
      "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "            0],\n",
      "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "            0],\n",
      "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "            0],\n",
      "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "            0],\n",
      "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "            0],\n",
      "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "            0],\n",
      "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "            0],\n",
      "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "            0],\n",
      "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "            0],\n",
      "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "            0]]], dtype=torch.int32), 'pool': tensor([[ 50, 117,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]],\n",
      "       dtype=torch.int32), 'pick_options': tensor([[ 82, 209, 134,  80, 239, 162, 106, 271,  25, 155, 297, 170,   0,   0,\n",
      "           0]], dtype=torch.int32)}\n",
      "tensor([[ -4.6162,  -6.5591, -12.5228, -12.9473,  -3.3594, -12.5033,  -6.5858,\n",
      "          -2.3911,  -9.8375,  -9.2691,  -0.1498, -11.1620, -14.4610, -14.4610,\n",
      "         -14.4610]], grad_fn=<SelectBackward0>)\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 28;\n",
       "                var nbb_unformatted_code = \"def get_preds(model: DraftTransformer, follower, card_ids):\\n    model.eval()\\n    hist = follower.history\\n    num_hist_rounds = len(follower.pool_card_ids)\\n    hist = [\\n        [card_ids.get(i, 0) for i in v]\\n        for n, (k, v) in enumerate(\\n            sorted(\\n                hist.items(),\\n                key=lambda x: int(x[0].split(\\\"_\\\")[0]) * 20 + int(x[0].split(\\\"_\\\")[1]),\\n            )\\n        )\\n        if n < num_hist_rounds\\n    ]\\n    valid_pick_options = [\\n        i for i in getattr(follower, \\\"pick_options\\\", []) if i in df.index\\n    ]\\n    valid_opt_names = follower.df.loc[valid_pick_options].name.values\\n    pick_options = [\\n        card_ids.get(i, 0) for i in follower.df.loc[valid_pick_options].name.values\\n    ]\\n    print(pick_options)\\n    valid_pool = [i for i in follower.pool_card_ids if i in df.index]\\n    pool = [card_ids.get(i, 0) for i in follower.df.loc[valid_pool].name.values]\\n\\n    batch = collate_batch(\\n        [\\n            {\\\"history\\\": hist, \\\"options\\\": pick_options, \\\"pool\\\": pool},\\n        ],\\n        device=\\\"cpu\\\",\\n        inference=True,\\n        n_cards_in_pack=15,\\n    )\\n    print(batch)\\n    card_logits, game_win_pred = model(batch)\\n    print(card_logits)\\n    card_probs = np.round(np.exp(card_logits.detach().numpy()[0]), 3)\\n    pred_df = pd.DataFrame(zip(valid_opt_names, card_probs), columns=[\\\"name\\\", \\\"pred\\\"])\\n    return pred_df, game_win_pred.detach().numpy()\\n\\n\\na, b = get_preds(model, follower, card_ids)\";\n",
       "                var nbb_formatted_code = \"def get_preds(model: DraftTransformer, follower, card_ids):\\n    model.eval()\\n    hist = follower.history\\n    num_hist_rounds = len(follower.pool_card_ids)\\n    hist = [\\n        [card_ids.get(i, 0) for i in v]\\n        for n, (k, v) in enumerate(\\n            sorted(\\n                hist.items(),\\n                key=lambda x: int(x[0].split(\\\"_\\\")[0]) * 20 + int(x[0].split(\\\"_\\\")[1]),\\n            )\\n        )\\n        if n < num_hist_rounds\\n    ]\\n    valid_pick_options = [\\n        i for i in getattr(follower, \\\"pick_options\\\", []) if i in df.index\\n    ]\\n    valid_opt_names = follower.df.loc[valid_pick_options].name.values\\n    pick_options = [\\n        card_ids.get(i, 0) for i in follower.df.loc[valid_pick_options].name.values\\n    ]\\n    print(pick_options)\\n    valid_pool = [i for i in follower.pool_card_ids if i in df.index]\\n    pool = [card_ids.get(i, 0) for i in follower.df.loc[valid_pool].name.values]\\n\\n    batch = collate_batch(\\n        [\\n            {\\\"history\\\": hist, \\\"options\\\": pick_options, \\\"pool\\\": pool},\\n        ],\\n        device=\\\"cpu\\\",\\n        inference=True,\\n        n_cards_in_pack=15,\\n    )\\n    print(batch)\\n    card_logits, game_win_pred = model(batch)\\n    print(card_logits)\\n    card_probs = np.round(np.exp(card_logits.detach().numpy()[0]), 3)\\n    pred_df = pd.DataFrame(zip(valid_opt_names, card_probs), columns=[\\\"name\\\", \\\"pred\\\"])\\n    return pred_df, game_win_pred.detach().numpy()\\n\\n\\na, b = get_preds(model, follower, card_ids)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_preds(model: DraftTransformer, follower, card_ids):\n",
    "    model.eval()\n",
    "    hist = follower.history\n",
    "    num_hist_rounds = len(follower.pool_card_ids)\n",
    "    hist = [\n",
    "        [card_ids.get(i, 0) for i in v]\n",
    "        for n, (k, v) in enumerate(\n",
    "            sorted(\n",
    "                hist.items(),\n",
    "                key=lambda x: int(x[0].split(\"_\")[0]) * 20 + int(x[0].split(\"_\")[1]),\n",
    "            )\n",
    "        )\n",
    "        if n < num_hist_rounds\n",
    "    ]\n",
    "    valid_pick_options = [\n",
    "        i for i in getattr(follower, \"pick_options\", []) if i in df.index\n",
    "    ]\n",
    "    valid_opt_names = follower.df.loc[valid_pick_options].name.values\n",
    "    pick_options = [\n",
    "        card_ids.get(i, 0) for i in follower.df.loc[valid_pick_options].name.values\n",
    "    ]\n",
    "    print(pick_options)\n",
    "    valid_pool = [i for i in follower.pool_card_ids if i in df.index]\n",
    "    pool = [card_ids.get(i, 0) for i in follower.df.loc[valid_pool].name.values]\n",
    "\n",
    "    batch = collate_batch(\n",
    "        [\n",
    "            {\"history\": hist, \"options\": pick_options, \"pool\": pool},\n",
    "        ],\n",
    "        device=\"cpu\",\n",
    "        inference=True,\n",
    "        n_cards_in_pack=15,\n",
    "    )\n",
    "    print(batch)\n",
    "    card_logits, game_win_pred = model(batch)\n",
    "    print(card_logits)\n",
    "    card_probs = np.round(np.exp(card_logits.detach().numpy()[0]), 3)\n",
    "    pred_df = pd.DataFrame(zip(valid_opt_names, card_probs), columns=[\"name\", \"pred\"])\n",
    "    return pred_df, game_win_pred.detach().numpy()\n",
    "\n",
    "\n",
    "a, b = get_preds(model, follower, card_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7929c44c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Unforgiving One'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 26;\n",
       "                var nbb_unformatted_code = \"inv = {v: k for k, v in card_ids.items()}\\ninv[297]\";\n",
       "                var nbb_formatted_code = \"inv = {v: k for k, v in card_ids.items()}\\ninv[297]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "inv = {v: k for k, v in card_ids.items()}\n",
    "inv[297]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f879071d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kindled Fury</td>\n",
       "      <td>0.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Golden-Tail Disciple</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gift of Wrath</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Explosive Entry</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Geothermal Kami</td>\n",
       "      <td>0.035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>The Modern Age</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Network Terminal</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Skyswimmer Koi</td>\n",
       "      <td>0.092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Automated Artificer</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Flame Discharge</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Unforgiving One</td>\n",
       "      <td>0.861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Norika Yamazaki, the Poet</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         name   pred\n",
       "0                Kindled Fury  0.010\n",
       "1        Golden-Tail Disciple  0.001\n",
       "2               Gift of Wrath  0.000\n",
       "3             Explosive Entry  0.000\n",
       "4             Geothermal Kami  0.035\n",
       "5              The Modern Age  0.000\n",
       "6            Network Terminal  0.001\n",
       "7              Skyswimmer Koi  0.092\n",
       "8         Automated Artificer  0.000\n",
       "9             Flame Discharge  0.000\n",
       "10            Unforgiving One  0.861\n",
       "11  Norika Yamazaki, the Poet  0.000"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 27;\n",
       "                var nbb_unformatted_code = \"a\";\n",
       "                var nbb_formatted_code = \"a\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "84e70953",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8693582353988059"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 19;\n",
       "                var nbb_unformatted_code = \"np.exp(-.14)\";\n",
       "                var nbb_formatted_code = \"np.exp(-0.14)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.exp(-0.14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cc8f16db",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "'b' is not in list",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_4992/4198621175.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;33m[\u001b[0m\u001b[1;34m'a'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'b'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m: 'b' is not in list"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 21;\n",
       "                var nbb_unformatted_code = \"['a'].index('b')\";\n",
       "                var nbb_formatted_code = \"[\\\"a\\\"].index(\\\"b\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "[\"a\"].index(\"b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d4bffe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
